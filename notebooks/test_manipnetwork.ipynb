{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256,)\n",
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "fp = \"modules/ManipNet/Code/Tensorflow/Data/ManipNetBIN/Encoder0_b0.bin\"\n",
    "array = np.fromfile(fp)\n",
    "print(array.shape)\n",
    "array = np.fromfile(fp, dtype=np.float32)\n",
    "print(array.shape)\n",
    "# print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder_b0 (214,)\n",
      "Decoder_w0 (328704,)\n",
      "DenseRes0_b0 (1536,)\n",
      "DenseRes0_w0 (2359296,)\n",
      "DenseRes1_b0 (1536,)\n",
      "DenseRes1_w0 (2359296,)\n",
      "DenseRes2_b0 (1536,)\n",
      "DenseRes2_w0 (2359296,)\n",
      "DenseRes3_b0 (1536,)\n",
      "DenseRes3_w0 (2359296,)\n",
      "Encoder0_b0 (512,)\n",
      "Encoder0_w0 (98304,)\n",
      "Encoder1_b0 (512,)\n",
      "Encoder1_w0 (172032,)\n",
      "Encoder2_b0 (512,)\n",
      "Encoder2_w0 (932864,)\n",
      "Xmean (2350,)\n",
      "Xstd (2350,)\n",
      "Ymean (214,)\n",
      "Ystd (214,)\n",
      "Using cuda device\n",
      "pose_fc.weight torch.Size([512, 192]) torch.Size([98304]) Encoder0_w0 torch.Size([98304])\n",
      "pose_fc.bias torch.Size([512]) torch.Size([512]) Encoder0_b0 torch.Size([512])\n",
      "traj_fc.weight torch.Size([512, 336]) torch.Size([172032]) Encoder1_w0 torch.Size([172032])\n",
      "traj_fc.bias torch.Size([512]) torch.Size([512]) Encoder1_b0 torch.Size([512])\n",
      "sensor_fc.weight torch.Size([512, 1822]) torch.Size([932864]) Encoder2_w0 torch.Size([932864])\n",
      "sensor_fc.bias torch.Size([512]) torch.Size([512]) Encoder2_b0 torch.Size([512])\n",
      "res0.FC.weight torch.Size([1536, 1536]) torch.Size([2359296]) DenseRes0_w0 torch.Size([2359296])\n",
      "res0.FC.bias torch.Size([1536]) torch.Size([1536]) DenseRes0_b0 torch.Size([1536])\n",
      "res1.FC.weight torch.Size([1536, 1536]) torch.Size([2359296]) DenseRes1_w0 torch.Size([2359296])\n",
      "res1.FC.bias torch.Size([1536]) torch.Size([1536]) DenseRes1_b0 torch.Size([1536])\n",
      "res2.FC.weight torch.Size([1536, 1536]) torch.Size([2359296]) DenseRes2_w0 torch.Size([2359296])\n",
      "res2.FC.bias torch.Size([1536]) torch.Size([1536]) DenseRes2_b0 torch.Size([1536])\n",
      "decoder_fc.weight torch.Size([214, 1536]) torch.Size([328704]) Decoder_w0 torch.Size([328704])\n",
      "decoder_fc.bias torch.Size([214]) torch.Size([214]) Decoder_b0 torch.Size([214])\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bindata = {}\n",
    "binpath = \"modules/ManipNet/Code/Tensorflow/Data/ManipNetBIN\"\n",
    "for fp in sorted(Path(binpath).iterdir()):\n",
    "    # print(fp)\n",
    "    bindata[fp.stem] = np.fromfile(fp, dtype=np.float32)\n",
    "for k, v in bindata.items():\n",
    "    print(k, v.shape)\n",
    "\n",
    "# os.chdir(\"data/ManipNetBIN\")\n",
    "# print(os.getcwd())\n",
    "# num = np.fromfile('Decoder_b0.bin')\n",
    "# print(num)\n",
    "\n",
    "# %%\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_vec, out_vec):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.FC = nn.Linear(in_vec, out_vec)\n",
    "    def __call__(self, H_zero):\n",
    "        H_zero = nn.ReLU(H_zero)\n",
    "        H_one = self.FC(H_zero) + H_zero\n",
    "        H_one  = nn.ReLU(H_one)\n",
    "        H_two = self.res_fc(H_one) + H_one + H_zero\n",
    "        return H_two\n",
    "\n",
    "# %%\n",
    "# 訓練に際して、可能であればGPU（cuda）を設定します。GPUが搭載されていない場合はCPUを使用します\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# modelを定義します\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.pose_fc = nn.Linear(192, 512)\n",
    "        self.traj_fc = nn.Linear(336, 512)\n",
    "        self.sensor_fc = nn.Linear(1822, 512)\n",
    "        self.res0 = ResBlock(1536, 1536)\n",
    "        self.res1 = ResBlock(1536, 1536)\n",
    "        self.res2 = ResBlock(1536, 1536)\n",
    "        self.decoder_fc = nn.Linear(1536, 214)\n",
    "\n",
    "    def forward(self, pose, traj, sensor):\n",
    "        x = self.flatten(x)\n",
    "        pose = self.pose_fc(pose)\n",
    "        traj = self.traj_fc(traj)\n",
    "        sensor = self.sensor_fc(sensor)\n",
    "        out = torch.cat(pose, traj, sensor, dim=1)\n",
    "        out = self.res1(out)\n",
    "        out = self.res2(out)\n",
    "        out = self.decoder_fc(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "# print(model)\n",
    "\n",
    "# %%\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(name, param.shape)\n",
    "\n",
    "# # %%\n",
    "# for k, v in bindata.items():\n",
    "#     print(k, v.shape)\n",
    "\n",
    "# %%\n",
    "# with torch.no_grad():\n",
    "#     for name, param in model.named_parameters():\n",
    "#         # 重み名がNumPy配列のキーと一致するかを確認\n",
    "#         print(name, param.flatten().shape)\n",
    "        # for k, v in bindata.items():\n",
    "        #     print(k, name)\n",
    "        #     if name == \"Decoder_b0.weight\":\n",
    "        #         print(name, param)\n",
    "        #         param.copy_(torch.from_numpy(bindata[\"Decoder_b0\"]))\n",
    "        #         print(\"called\")\n",
    "        #         print(name, param)\n",
    "        #     if name == \"Decoder_w0.weight\":\n",
    "        #         print(name, param)\n",
    "        #         param.copy_(torch.from_numpy(bindata[\"Decoder_w0\"]))\n",
    "        #         print(\"called\")\n",
    "        #         print(name, param)\n",
    "        #         # 重みを適用（形状が一致している必要がある）\n",
    "        #         # param.copy_(torch.from_numpy(bindata[k]))     \n",
    "\n",
    "# %%\n",
    "getbinname = {\n",
    "    \"decoder_fc.weight\": \"Decoder_w0\",\n",
    "    \"decoder_fc.bias\": \"Decoder_b0\",\n",
    "    \"pose_fc.weight\": \"Encoder0_w0\",\n",
    "    \"pose_fc.bias\": \"Encoder0_b0\",\n",
    "    \"traj_fc.weight\": \"Encoder1_w0\",\n",
    "    \"traj_fc.bias\": \"Encoder1_b0\",\n",
    "    \"sensor_fc.weight\": \"Encoder2_w0\",\n",
    "    \"sensor_fc.bias\": \"Encoder2_b0\",\n",
    "    \"res0.FC.weight\": \"DenseRes0_w0\",\n",
    "    \"res0.FC.bias\": \"DenseRes0_b0\",\n",
    "    \"res1.FC.weight\": \"DenseRes1_w0\",\n",
    "    \"res1.FC.bias\": \"DenseRes1_b0\",\n",
    "    \"res2.FC.weight\": \"DenseRes2_w0\",\n",
    "    \"res2.FC.bias\": \"DenseRes2_b0\",\n",
    "}\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for name, param in model.named_parameters():\n",
    "        binname = getbinname.get(name, None)\n",
    "        if binname is not None:\n",
    "            binweight = torch.from_numpy(bindata[binname])\n",
    "            print(name, param.shape, param.flatten().shape, binname, binweight.shape)\n",
    "        else:\n",
    "            print(name, param.shape, param.flatten().shape)\n",
    "        # for k, v in bindata.items():\n",
    "        #     # print(name, k)\n",
    "        #     if name == \"Decoder_b0.weight\":\n",
    "        #         rephape_weight = torch.reshape(torch.from_numpy(bindata[\"Decoder_w0\"]), [107, -1])\n",
    "        #         # param.copy_(rephape_weight)\n",
    "        #     if name == \"Decoder_b0.bias\":\n",
    "        #         rephape_weight = torch.reshape(torch.from_numpy(bindata[\"Decoder_b0\"]), [107])\n",
    "        #         # param.copy_(rephape_weight)\n",
    "        #     if name == \"pose_fc.weight\":\n",
    "        #         rephape_weight = torch.reshape(torch.from_numpy(bindata[\"Encoder0_w0\"]), [256, 192])\n",
    "        #         # param.copy_(rephape_weight)\n",
    "        #     if name == \"pose_fc.bias\":\n",
    "        #         rephape_weight = torch.reshape(torch.from_numpy(bindata[\"Encoder0_b0\"]), [256])\n",
    "        #         # param.copy_(rephape_weight)\n",
    "        #     if name == \"traj_fc.weight\":\n",
    "        #         rephape_weight = torch.reshape(torch.from_numpy(bindata[\"Encoder1_w0\"]), [256, 336])\n",
    "        #         # param.copy_(rephape_weight)\n",
    "        #     if name == \"traj_fc.bias\":\n",
    "        #         rephape_weight = torch.reshape(torch.from_numpy(bindata[\"Encoder1_b0\"]), [256])\n",
    "        #         # param.copy_(rephape_weight)\n",
    "        #     if name == \"sensor_fc.weight\":\n",
    "        #         rephape_weight = torch.reshape(torch.from_numpy(bindata[\"Encoder2_w0\"]), [256, 1822])\n",
    "        #         # param.copy_(rephape_weight)\n",
    "        #     if name == \"sensor_fc.bias\":\n",
    "        #         rephape_weight = torch.reshape(torch.from_numpy(bindata[\"Encoder2_b0\"]), [256])\n",
    "        #         # param.copy_(rephape_weight)\n",
    "        #     print(name, param.shape, rephape_weight.shape)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "render-hand",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
