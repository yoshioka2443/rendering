{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Encoder NN\n",
    "start_traj = 192\n",
    "start_dis = 528\n",
    "start_end = 2350\n",
    "\n",
    "index_encoder0 = np.arange(0, start_traj)\n",
    "dim_encoder0 = [512]\n",
    "activation_encoder0 = [0]\n",
    "\n",
    "index_encoder1 = np.arange(start_traj, start_dis)\n",
    "dim_encoder1 = [512]\n",
    "activation_encoder1 = [0]\n",
    "\n",
    "index_encoder2 = np.arange(start_dis, start_end)\n",
    "dim_encoder2 = [512]\n",
    "activation_encoder2 = [0]\n",
    "\n",
    "\n",
    "index_encoders = [index_encoder0, index_encoder1, index_encoder2]\n",
    "dim_encoders = [dim_encoder0, dim_encoder1, dim_encoder2]\n",
    "activation_encoders = [activation_encoder0, activation_encoder1, activation_encoder2]\n",
    "\n",
    "# Keep prob\n",
    "keep_prob_main = 0.7\n",
    "keep_prob_encoders = [0.7, 0.7, 0.7]\n",
    "\n",
    "\n",
    "\n",
    "# Tuning para\n",
    "learning_rate = 0.0001\n",
    "\n",
    "def main():\n",
    "    GPU_Occupancy = 0.9\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=GPU_Occupancy)\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "    mann = MainNN()\n",
    "    mann.BuildModel(load_path, save_path,\n",
    "                    type_normalization,\n",
    "                    hiddenDim=hiddenDim,\n",
    "                    activations=activations,\n",
    "\n",
    "                    index_encoders=index_encoders,\n",
    "                    dim_encoders=dim_encoders,\n",
    "                    activation_encoders=activation_encoders)\n",
    "    mann.Train(sess,\n",
    "               # Model name for Saving\n",
    "               name_model,\n",
    "               # Flag/Path of test data\n",
    "               path_test=test_path,\n",
    "               flag_save_bin = True,\n",
    "               step_save=100, max_save=3,\n",
    "               # HyperParameters\n",
    "               keep_prob_main=keep_prob_main, batch_size=32, epoch=500, learning_rate_ini=learning_rate,\n",
    "               keep_prob_encoders=keep_prob_encoders\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (pose_fc): Linear(in_features=198, out_features=512, bias=True)\n",
      "  (traj_fc): Linear(in_features=336, out_features=512, bias=True)\n",
      "  (sensor_fc): Linear(in_features=1822, out_features=512, bias=True)\n",
      "  (res_fc): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "  (decoder_fc): Linear(in_features=1536, out_features=220, bias=True)\n",
      "  (Residual_Dence_Block): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 訓練に際して、可能であればGPU（cuda）を設定します。GPUが搭載されていない場合はCPUを使用します\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# modelを定義します\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.pose_fc = nn.Linear(198, 512)\n",
    "        self.traj_fc = nn.Linear(336, 512)\n",
    "        self.sensor_fc = nn.Linear(1822, 512)\n",
    "        self.res_fc = nn.Linear(1536, 1536)\n",
    "        self.decoder_fc = nn.Linear(1536, 220)\n",
    "        # まとめたいけど、わからん\n",
    "        self.Residual_Dence_Block = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1536, 1536),\n",
    "        )\n",
    "\n",
    "    def forward(self, pose, traj, sensor):\n",
    "        x = self.flatten(x)\n",
    "        pose = self.pose_fc(pose)\n",
    "        traj = self.traj_fc(traj)\n",
    "        sensor = self.sensor_fc(sensor)\n",
    "        H_zero = torch.cat(pose, traj, sensor, dim=1)\n",
    "        H_zero  = nn.ReLU(H_zero)\n",
    "        H_one = self.res_fc(H_zero) + H_zero\n",
    "        H_one  = nn.ReLU(H_one)\n",
    "        H_two = self.res_fc(H_one) + H_one + H_zero\n",
    "        H_two  = nn.ReLU(H_two)\n",
    "        H_three = self.res_fc(H_two) + H_two\n",
    "        H_three  = nn.ReLU(H_three)\n",
    "        H_four = self.res_fc(H_three) + H_three + H_two\n",
    "        out = self.decoder_fc(H_four)\n",
    "        return out\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "# net.state_dict()['conv1.weight'][0] = torch.tensor([conv1の新しいパラメータ])\n",
    "# print(net.state_dict()['conv1.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
