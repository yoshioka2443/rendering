{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/rendering/data\n",
      "/workspace/rendering\n",
      "Decoder_b0 (214,)\n",
      "Decoder_w0 (328704,)\n",
      "DenseRes0_b0 (1536,)\n",
      "DenseRes0_w0 (2359296,)\n",
      "DenseRes1_b0 (1536,)\n",
      "DenseRes1_w0 (2359296,)\n",
      "DenseRes2_b0 (1536,)\n",
      "DenseRes2_w0 (2359296,)\n",
      "DenseRes3_b0 (1536,)\n",
      "DenseRes3_w0 (2359296,)\n",
      "Encoder0_b0 (512,)\n",
      "Encoder0_w0 (98304,)\n",
      "Encoder1_b0 (512,)\n",
      "Encoder1_w0 (172032,)\n",
      "Encoder2_b0 (512,)\n",
      "Encoder2_w0 (932864,)\n",
      "Xmean (2350,)\n",
      "Xstd (2350,)\n",
      "Ymean (214,)\n",
      "Ystd (214,)\n",
      "/workspace/rendering/data/ManipNetBIN\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "bindata = {}\n",
    "for fp in sorted(Path(\"data/ManipNetBIN\").iterdir()):\n",
    "    # print(fp)\n",
    "    bindata[fp.stem] = np.fromfile(fp, dtype=np.float32)\n",
    "for k, v in bindata.items():\n",
    "    print(k, v.shape)\n",
    "\n",
    "os.chdir(\"data/ManipNetBIN\")\n",
    "print(os.getcwd())\n",
    "# num = np.fromfile('Decoder_b0.bin')\n",
    "# print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock():\n",
    "    def __init__(self, in_vec, out_vec):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.FC0= nn.Linear(in_vec, out_vec)\n",
    "        self.FC1 = nn.Linear(in_vec, out_vec)\n",
    "    def __call__(self, H_zero):\n",
    "        H_zero = nn.ReLU(H_zero)\n",
    "        H_one = self.FC0(H_zero) + H_zero\n",
    "        H_one  = nn.ReLU(H_one)\n",
    "        H_two = self.FC1(H_one) + H_one + H_zero\n",
    "        return H_two\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (Decoder): Linear(in_features=1536, out_features=214, bias=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (Encoder0): Linear(in_features=192, out_features=512, bias=True)\n",
      "  (Encoder1): Linear(in_features=336, out_features=512, bias=True)\n",
      "  (Encoder2): Linear(in_features=1822, out_features=512, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 訓練に際して、可能であればGPU（cuda）を設定します。GPUが搭載されていない場合はCPUを使用します\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# modelを定義します\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.Decoder = nn.Linear(1536, 214)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.Encoder0= nn.Linear(192, 512)\n",
    "        self.Encoder1 = nn.Linear(336, 512)\n",
    "        self.Encoder2 = nn.Linear(1822, 512)\n",
    "        # self.res_fc = nn.Linear(1536, 1536)\n",
    "        self.DenseRes0 = ResBlock(1536, 1536)\n",
    "        self.DenseRes1 = ResBlock(1536, 1536)\n",
    "\n",
    "    def forward(self, pose, traj, sensor):\n",
    "        x = self.flatten(x)\n",
    "        pose = self.Encoder0(pose)\n",
    "        traj = self.Encoder1(traj)\n",
    "        sensor = self.Encoder2(sensor)\n",
    "        out = torch.cat(pose, traj, sensor, dim=1)\n",
    "        out = self.DenseRes0(out)\n",
    "        out = self.DenseRes1(out)\n",
    "        out = self.Decoder(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder.weight torch.Size([214, 1536])\n",
      "Decoder.bias torch.Size([214])\n",
      "Encoder0.weight torch.Size([512, 192])\n",
      "Encoder0.bias torch.Size([512])\n",
      "Encoder1.weight torch.Size([512, 336])\n",
      "Encoder1.bias torch.Size([512])\n",
      "Encoder2.weight torch.Size([512, 1822])\n",
      "Encoder2.bias torch.Size([512])\n",
      "res_fc.weight torch.Size([1536, 1536])\n",
      "res_fc.bias torch.Size([1536])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder_b0 (214,)\n",
      "Decoder_w0 (328704,)\n",
      "DenseRes0_b0 (1536,)\n",
      "DenseRes0_w0 (2359296,)\n",
      "DenseRes1_b0 (1536,)\n",
      "DenseRes1_w0 (2359296,)\n",
      "DenseRes2_b0 (1536,)\n",
      "DenseRes2_w0 (2359296,)\n",
      "DenseRes3_b0 (1536,)\n",
      "DenseRes3_w0 (2359296,)\n",
      "Encoder0_b0 (512,)\n",
      "Encoder0_w0 (98304,)\n",
      "Encoder1_b0 (512,)\n",
      "Encoder1_w0 (172032,)\n",
      "Encoder2_b0 (512,)\n",
      "Encoder2_w0 (932864,)\n",
      "Xmean (2350,)\n",
      "Xstd (2350,)\n",
      "Ymean (214,)\n",
      "Ystd (214,)\n"
     ]
    }
   ],
   "source": [
    "for k, v in bindata.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Decoder', 'Encoder0', 'Encoder1', 'Encoder2']\n",
      "[['Decoder.weight', 'Decoder_w0', [214, 1536]], ['Decoder.bias', 'Decoder_b0', [214]], ['Encoder0.weight', 'Encoder0_w0', [512, 192]], ['Encoder0.bias', 'Encoder0_b0', [512]], ['Encoder1.weight', 'Encoder1_w0', [512, 336]], ['Encoder1.bias', 'Encoder1_b0', [512]], ['Encoder2.weight', 'Encoder2_w0', [512, 1822]], ['Encoder2.bias', 'Encoder2_b0', [512]]]\n"
     ]
    }
   ],
   "source": [
    "netlist = [\"Decoder\"]\n",
    "net_name_list = []\n",
    "# for i in range(4):\n",
    "#     netlist.append(\"DenseRes\" + str(i))\n",
    "for i in range(3):\n",
    "    netlist.append(\"Encoder\" + str(i))\n",
    "print(netlist)\n",
    "for name in netlist:\n",
    "    net_name_list.append([name + \".weight\", name + \"_w0\"])\n",
    "    net_name_list.append([name + \".bias\", name + \"_b0\"])\n",
    "\n",
    "shape_list = [[214, 1536], [214], [512, 192], [512], [512, 336], [512], [512, 1822], [512]]\n",
    "for i in range(len(net_name_list)):\n",
    "    net_name_list[i].append(shape_list[i])\n",
    "print(net_name_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder.weight\n",
      "torch.Size([214, 1536]) Decoder.weight Decoder_w0\n",
      "Decoder.bias\n",
      "torch.Size([214]) Decoder.bias Decoder_b0\n",
      "Encoder0.weight\n",
      "torch.Size([512, 192]) Encoder0.weight Encoder0_w0\n",
      "Encoder0.bias\n",
      "torch.Size([512]) Encoder0.bias Encoder0_b0\n",
      "Encoder1.weight\n",
      "torch.Size([512, 336]) Encoder1.weight Encoder1_w0\n",
      "Encoder1.bias\n",
      "torch.Size([512]) Encoder1.bias Encoder1_b0\n",
      "Encoder2.weight\n",
      "torch.Size([512, 1822]) Encoder2.weight Encoder2_w0\n",
      "Encoder2.bias\n",
      "torch.Size([512]) Encoder2.bias Encoder2_b0\n",
      "Linear(in_features=192, out_features=512, bias=True)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NeuralNetwork' object has no attribute 'DenceRes0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m                 model\u001b[38;5;241m.\u001b[39mres1\u001b[38;5;241m.\u001b[39mFC\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mEncoder0)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDenceRes0\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/envs/py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NeuralNetwork' object has no attribute 'DenceRes0'"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name)\n",
    "        for k, v in bindata.items():\n",
    "            for i in range(len(net_name_list)):\n",
    "                # print(net_name_list[i][0], name)\n",
    "                if name == net_name_list[i][0] and k == net_name_list[i][1]:\n",
    "                    print(param.shape, name, k)\n",
    "                    rephape_weight = torch.reshape(torch.from_numpy(bindata[net_name_list[i][1]]), net_name_list[i][2])\n",
    "                    param.copy_(rephape_weight)\n",
    "        \n",
    "            # resblock \n",
    "            if name == \"DenseRes0_b0\":\n",
    "                model.res1.FC.parameters.copy()\n",
    "    \n",
    "print(model.Encoder0)\n",
    "print(model.DenceRes0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Linear(in_features=1536, out_features=1536, bias=True)>\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
