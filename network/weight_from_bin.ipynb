{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shugo/workspace/rendering/network\n",
      "/home/shugo/workspace/rendering\n",
      "Decoder_b0 (214,)\n",
      "Decoder_w0 (328704,)\n",
      "DenseRes0_b0 (1536,)\n",
      "DenseRes0_w0 (2359296,)\n",
      "DenseRes1_b0 (1536,)\n",
      "DenseRes1_w0 (2359296,)\n",
      "DenseRes2_b0 (1536,)\n",
      "DenseRes2_w0 (2359296,)\n",
      "DenseRes3_b0 (1536,)\n",
      "DenseRes3_w0 (2359296,)\n",
      "Encoder0_b0 (512,)\n",
      "Encoder0_w0 (98304,)\n",
      "Encoder1_b0 (512,)\n",
      "Encoder1_w0 (172032,)\n",
      "Encoder2_b0 (512,)\n",
      "Encoder2_w0 (932864,)\n",
      "Xmean (2350,)\n",
      "Xstd (2350,)\n",
      "Ymean (214,)\n",
      "Ystd (214,)\n",
      "/home/shugo/workspace/rendering/data/ManipNetBIN\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "bindata = {}\n",
    "for fp in sorted(Path(\"data/ManipNetBIN\").iterdir()):\n",
    "    # print(fp)\n",
    "    bindata[fp.stem] = np.fromfile(fp, dtype=np.float32)\n",
    "for k, v in bindata.items():\n",
    "    print(k, v.shape)\n",
    "\n",
    "os.chdir(\"data/ManipNetBIN\")\n",
    "print(os.getcwd())\n",
    "# num = np.fromfile('Decoder_b0.bin')\n",
    "# print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_vec, out_vec):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.FC0= nn.Linear(in_vec, out_vec)\n",
    "        self.FC1 = nn.Linear(in_vec, out_vec)\n",
    "        # self.relu = nn.ReLU()\n",
    "\n",
    "        # self.sequence = nn.Sequential(\n",
    "        #     [\n",
    "        #         nn.Linear(),\n",
    "        #         nn.ReLU(),\n",
    "        #     ]\n",
    "        # )\n",
    "\n",
    "    def __call__(self, H_zero):\n",
    "        # H_zero = nn.ReLU(H_zero)\n",
    "        H_zero_ = F.relu(H_zero)\n",
    "        H_one = self.FC0(H_zero_) + H_zero_\n",
    "        # H_one  = nn.ReLU(H_one)\n",
    "        H_one_ = F.relu(H_one)\n",
    "        H_two = self.FC1(H_one_) + H_one_ + H_zero_\n",
    "        return H_two\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n",
      "cuda:0\n",
      "NeuralNetwork(\n",
      "  (Encoder0): Linear(in_features=192, out_features=512, bias=True)\n",
      "  (Encoder1): Linear(in_features=336, out_features=512, bias=True)\n",
      "  (Encoder2): Linear(in_features=1822, out_features=512, bias=True)\n",
      "  (DenseRes0): ResBlock(\n",
      "    (FC0): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (FC1): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "  )\n",
      "  (DenseRes1): ResBlock(\n",
      "    (FC0): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (FC1): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "  )\n",
      "  (Decoder): Linear(in_features=1536, out_features=214, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 訓練に際して、可能であればGPU（cuda）を設定します。GPUが搭載されていない場合はCPUを使用します\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# modelを定義します\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.Encoder0= nn.Linear(192, 512)\n",
    "        self.Encoder1 = nn.Linear(336, 512)\n",
    "        self.Encoder2 = nn.Linear(1822, 512)\n",
    "        self.DenseRes0 = ResBlock(1536, 1536)\n",
    "        self.DenseRes1 = ResBlock(1536, 1536)\n",
    "        self.Decoder = nn.Linear(1536, 214)\n",
    "\n",
    "    def forward(self, pose, traj, sensor):\n",
    "        pose_ = self.Encoder0(pose)\n",
    "        traj_ = self.Encoder1(traj)\n",
    "        sensor_ = self.Encoder2(sensor)\n",
    "        out = torch.cat([pose_, traj_, sensor_], dim=-1)\n",
    "        out = self.DenseRes0(out)\n",
    "        out = self.DenseRes1(out)\n",
    "        out = self.Decoder(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(device)\n",
    "print(model)\n",
    "# model()\n",
    "# print(model.device)\n",
    "# for param in model.Encoder1.parameters():\n",
    "#     print(\"encoder\", param.shape)\n",
    "pose, traj, sensor = torch.zeros([1,192]).to(device), torch.zeros([1,336]).to(device), torch.zeros([1,1822]).to(device)\n",
    "y = model(pose, traj, sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder0.weight torch.float32\n",
      "Encoder0.bias torch.float32\n",
      "Encoder1.weight torch.float32\n",
      "Encoder1.bias torch.float32\n",
      "Encoder2.weight torch.float32\n",
      "Encoder2.bias torch.float32\n",
      "DenseRes0.FC0.weight torch.float32\n",
      "DenseRes0.FC0.bias torch.float32\n",
      "DenseRes0.FC1.weight torch.float32\n",
      "DenseRes0.FC1.bias torch.float32\n",
      "DenseRes1.FC0.weight torch.float32\n",
      "DenseRes1.FC0.bias torch.float32\n",
      "DenseRes1.FC1.weight torch.float32\n",
      "DenseRes1.FC1.bias torch.float32\n",
      "Decoder.weight torch.float32\n",
      "Decoder.bias torch.float32\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.dtype)\n",
    "    # print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder0.weight torch.Size([512, 192])\n",
      "Encoder0.bias torch.Size([512])\n",
      "Encoder1.weight torch.Size([512, 336])\n",
      "Encoder1.bias torch.Size([512])\n",
      "Encoder2.weight torch.Size([512, 1822])\n",
      "Encoder2.bias torch.Size([512])\n",
      "DenseRes0.FC0.weight torch.Size([1536, 1536])\n",
      "DenseRes0.FC0.bias torch.Size([1536])\n",
      "DenseRes0.FC1.weight torch.Size([1536, 1536])\n",
      "DenseRes0.FC1.bias torch.Size([1536])\n",
      "DenseRes1.FC0.weight torch.Size([1536, 1536])\n",
      "DenseRes1.FC0.bias torch.Size([1536])\n",
      "DenseRes1.FC1.weight torch.Size([1536, 1536])\n",
      "DenseRes1.FC1.bias torch.Size([1536])\n",
      "Decoder.weight torch.Size([214, 1536])\n",
      "Decoder.bias torch.Size([214])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder_b0 (214,)\n",
      "Decoder_w0 (328704,)\n",
      "DenseRes0_b0 (1536,)\n",
      "DenseRes0_w0 (2359296,)\n",
      "DenseRes1_b0 (1536,)\n",
      "DenseRes1_w0 (2359296,)\n",
      "DenseRes2_b0 (1536,)\n",
      "DenseRes2_w0 (2359296,)\n",
      "DenseRes3_b0 (1536,)\n",
      "DenseRes3_w0 (2359296,)\n",
      "Encoder0_b0 (512,)\n",
      "Encoder0_w0 (98304,)\n",
      "Encoder1_b0 (512,)\n",
      "Encoder1_w0 (172032,)\n",
      "Encoder2_b0 (512,)\n",
      "Encoder2_w0 (932864,)\n",
      "Xmean (2350,)\n",
      "Xstd (2350,)\n",
      "Ymean (214,)\n",
      "Ystd (214,)\n"
     ]
    }
   ],
   "source": [
    "for k, v in bindata.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Decoder', 'Encoder0', 'Encoder1', 'Encoder2']\n",
      "[['Decoder.weight', 'Decoder_w0', [214, 1536]], ['Decoder.bias', 'Decoder_b0', [214]], ['Encoder0.weight', 'Encoder0_w0', [512, 192]], ['Encoder0.bias', 'Encoder0_b0', [512]], ['Encoder1.weight', 'Encoder1_w0', [512, 336]], ['Encoder1.bias', 'Encoder1_b0', [512]], ['Encoder2.weight', 'Encoder2_w0', [512, 1822]], ['Encoder2.bias', 'Encoder2_b0', [512]]]\n"
     ]
    }
   ],
   "source": [
    "netlist = [\"Decoder\"]\n",
    "net_name_list = []\n",
    "# for i in range(4):\n",
    "#     netlist.append(\"DenseRes\" + str(i))\n",
    "for i in range(3):\n",
    "    netlist.append(\"Encoder\" + str(i))\n",
    "print(netlist)\n",
    "for name in netlist:\n",
    "    net_name_list.append([name + \".weight\", name + \"_w0\"])\n",
    "    net_name_list.append([name + \".bias\", name + \"_b0\"])\n",
    "\n",
    "shape_list = [[214, 1536], [214], [512, 192], [512], [512, 336], [512], [512, 1822], [512]]\n",
    "for i in range(len(net_name_list)):\n",
    "    net_name_list[i].append(shape_list[i])\n",
    "print(net_name_list)\n",
    "\n",
    "dense_weight_list = []\n",
    "dense_bias_list = []\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        dense_weight_list.append([\"DenseRes\" + str(i) + \".FC\" + str(j) + \".weight\", \"DenseRes\" + str(2 * i + j) + \"_w0\"])\n",
    "        dense_bias_list.append([\"DenseRes\" + str(i) + \".FC\" + str(j) + \".bias\", \"DenseRes\" + str(2 * i + j) + \"_b0\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder0.weight Encoder0_w0\n",
      "(98304,)\n",
      "torch.Size([512, 192])\n",
      "Parameter containing:\n",
      "tensor([[-0.0751, -0.0893,  0.0815,  ..., -0.0590, -0.0180, -0.0058],\n",
      "        [-0.0455,  0.0524, -0.0306,  ..., -0.1515,  0.0012, -0.0810],\n",
      "        [-0.0329,  0.0703, -0.0476,  ...,  0.0215,  0.0864, -0.0461],\n",
      "        ...,\n",
      "        [ 0.0060,  0.0643, -0.0282,  ...,  0.0144,  0.0069, -0.0084],\n",
      "        [-0.0182,  0.0615,  0.0271,  ...,  0.0547,  0.0410, -0.0219],\n",
      "        [-0.0358,  0.0303,  0.0649,  ..., -0.0151, -0.1224, -0.0107]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "[-0.07508604 -0.08928403  0.08154082 ... -0.01513198 -0.12243388\n",
      " -0.01070601]\n",
      "Encoder0.bias Encoder0_b0\n",
      "(512,)\n",
      "torch.Size([512])\n",
      "Parameter containing:\n",
      "tensor([-4.3906e-01,  4.7862e-02, -1.1680e+00, -1.3886e+00, -5.3770e-01,\n",
      "        -3.2809e-01,  1.0509e+00, -4.4401e-01, -7.2452e-01, -3.2332e-01,\n",
      "        -9.3679e-01, -7.6667e-01, -7.8083e-01, -1.1598e+00, -9.9273e-01,\n",
      "        -1.1866e+00, -4.9976e-01, -1.4072e-01, -6.7747e-01, -6.7173e-01,\n",
      "        -1.0881e+00, -8.0475e-02, -6.2963e-01, -1.3231e+00, -6.4958e-01,\n",
      "        -1.0807e+00, -1.9882e-01, -9.7029e-01, -6.6112e-01, -9.4134e-01,\n",
      "        -3.9715e-01, -1.6274e-01, -3.1258e-01,  9.7770e-01,  1.5371e-01,\n",
      "         2.8020e-01, -7.7931e-01, -5.4925e-01,  1.6257e+00, -2.7447e-01,\n",
      "        -1.8523e+00, -4.0375e-01, -6.0161e-01, -4.4085e-01, -1.1014e+00,\n",
      "        -4.3666e-01,  2.3903e-01, -8.7425e-01, -1.1901e+00, -5.1821e-01,\n",
      "        -7.7406e-01, -1.0964e+00, -7.0872e-01,  5.9568e-03, -2.6934e-01,\n",
      "         2.1699e-01, -8.3018e-01, -4.2144e-01, -5.7552e-01, -7.2930e-01,\n",
      "        -2.2320e-01, -7.6321e-01, -1.0170e+00, -8.7127e-01, -3.3961e-01,\n",
      "        -8.3208e-01, -8.1641e-01,  1.0962e+00,  1.7797e+00,  1.8376e+00,\n",
      "        -2.9112e-01,  4.3535e-01, -9.8477e-01,  7.7229e-01, -2.9684e-01,\n",
      "        -9.8708e-01, -2.4607e-01, -7.3421e-01,  1.7074e-01, -8.1644e-01,\n",
      "        -7.4658e-01, -5.3343e-01,  2.0174e+00,  5.1982e-03, -3.0636e-01,\n",
      "        -2.3099e-01,  5.0989e-01, -7.5494e-01, -6.0530e-01,  4.2969e-01,\n",
      "        -3.8006e-01,  1.0005e+00, -9.3268e-01,  8.8310e-01,  1.2754e-01,\n",
      "        -8.1616e-01,  6.0620e-01, -4.9828e-01,  1.2382e-01, -2.6718e-01,\n",
      "        -3.9277e-01, -4.0351e-01, -7.8099e-01, -1.2827e+00, -7.2650e-01,\n",
      "         5.4563e-01, -8.3307e-01, -7.7926e-01, -2.1250e-01,  6.5009e-01,\n",
      "         1.8335e+00, -7.4290e-01, -3.4202e-01, -5.1086e-01, -1.0663e+00,\n",
      "        -1.5132e+00, -3.5368e-01, -7.6293e-01, -6.2816e-01, -1.9000e-01,\n",
      "        -6.8390e-01, -3.0178e-01, -8.2513e-01, -5.6426e-01, -4.7421e-01,\n",
      "        -8.5716e-01, -1.3030e+00,  9.5865e-01,  5.5428e-01, -8.2920e-01,\n",
      "        -9.5624e-01, -1.0177e+00,  4.6339e-01, -7.5144e-01, -1.1246e+00,\n",
      "        -7.1639e-01,  1.7148e-02, -9.8364e-01, -1.8453e-01,  6.0390e-02,\n",
      "         2.0198e-01, -4.4712e-02,  2.5073e-01, -7.4218e-02, -6.6577e-01,\n",
      "         8.5910e-01, -2.1423e-01,  6.8852e-01, -5.0640e-01, -6.3089e-01,\n",
      "        -1.9629e-01,  4.3821e-01,  8.5665e-01,  5.9313e-01,  1.1447e+00,\n",
      "        -9.6194e-01,  8.5572e-01, -6.6428e-01, -3.5137e-01, -3.6053e-01,\n",
      "        -8.4458e-01, -9.3414e-01,  9.5905e-01,  1.8786e+00,  8.3379e-01,\n",
      "        -7.6697e-01, -1.1236e+00, -4.8948e-01, -4.2710e-01, -8.3379e-01,\n",
      "        -1.1784e+00, -7.0696e-01,  9.6434e-01, -1.0633e+00, -1.0658e+00,\n",
      "        -7.8421e-01,  3.0586e-01, -6.2769e-01, -7.6692e-01, -3.0207e-01,\n",
      "         5.9897e-02, -4.5004e-01,  5.8605e-01, -1.3992e+00,  1.6111e+00,\n",
      "        -1.1569e+00, -8.5366e-01, -1.3812e+00, -1.1454e+00, -4.7291e-01,\n",
      "        -8.4193e-01, -1.1232e+00, -1.1582e+00, -9.4163e-01, -1.4452e+00,\n",
      "        -1.4311e-02, -1.3391e-01, -8.5392e-01, -3.2729e-01, -1.9344e-01,\n",
      "        -7.8315e-02, -7.7213e-02, -1.0502e+00, -6.3931e-03,  5.0279e-01,\n",
      "        -7.9887e-01, -4.5790e-01, -7.9856e-01, -1.2413e+00, -7.7535e-01,\n",
      "        -8.1358e-01, -6.4471e-02,  7.7888e-01, -5.7556e-01, -3.8360e-01,\n",
      "         4.3966e-02, -3.3451e-01, -6.8106e-01, -9.7699e-01,  4.8581e-01,\n",
      "        -4.7522e-01, -6.2595e-01, -8.0131e-01, -9.3152e-01, -8.2370e-01,\n",
      "        -8.4971e-01,  2.5732e-02, -5.0579e-01, -1.2371e+00,  9.1078e-02,\n",
      "        -6.4143e-01,  1.4353e+00, -1.2896e-01, -4.5717e-01, -5.3357e-01,\n",
      "         1.6357e+00,  4.9011e-01, -1.1034e+00, -5.4421e-01,  1.6217e+00,\n",
      "        -3.3295e-01,  1.4743e+00, -1.2668e+00, -1.5143e+00, -6.9948e-01,\n",
      "        -9.3250e-01, -9.2580e-01,  8.2835e-01, -8.6974e-01, -6.6888e-01,\n",
      "        -1.0857e+00, -6.4139e-01, -8.7056e-01, -9.3600e-01,  1.2207e+00,\n",
      "         1.6625e-01, -3.0974e-01, -9.0889e-01, -1.4639e+00, -8.6248e-01,\n",
      "        -7.4395e-02,  1.2609e+00, -5.8373e-01, -3.3057e-02,  9.6363e-02,\n",
      "        -6.5085e-01, -1.0799e+00, -5.1537e-01, -6.7712e-01, -4.2395e-01,\n",
      "        -1.0789e+00,  1.1202e+00, -8.5289e-01, -9.9582e-01, -7.2808e-01,\n",
      "         7.7262e-01, -7.6762e-01, -1.4577e+00, -6.1644e-01, -5.9999e-01,\n",
      "        -1.0225e+00, -1.1600e+00, -6.8821e-01,  6.0551e-02, -9.3566e-01,\n",
      "        -6.9541e-01, -2.3897e-01, -6.5867e-01,  1.2061e+00,  7.8379e-01,\n",
      "        -7.3333e-01, -8.1682e-01, -1.2977e+00,  1.2979e+00, -6.4435e-01,\n",
      "        -1.1958e-01,  1.2668e+00, -8.6745e-01, -6.2423e-01, -5.5419e-01,\n",
      "         5.9595e-01, -5.2042e-02,  9.8364e-01, -9.8834e-01, -9.3627e-01,\n",
      "        -1.2083e+00, -8.7637e-01,  7.8258e-01,  1.4542e-02,  8.7818e-01,\n",
      "        -4.4684e-01,  3.5432e-02, -3.7621e-01, -6.5344e-01, -1.0211e+00,\n",
      "         2.4372e-01, -1.0660e+00, -3.7948e-01, -1.9310e-01, -9.1725e-01,\n",
      "        -5.6280e-01,  8.9085e-01, -6.2629e-01, -6.7245e-01, -7.7291e-01,\n",
      "        -2.2979e-01,  8.0685e-01, -4.9420e-01, -7.5227e-01, -6.1668e-01,\n",
      "        -1.5337e-01, -3.7693e-01, -1.2383e+00, -3.1109e-01, -1.1811e+00,\n",
      "        -7.6794e-01, -8.8006e-01, -1.3393e-01,  1.0998e+00, -7.0404e-01,\n",
      "         4.9956e-01, -1.1982e+00, -5.2051e-01, -9.2728e-01, -1.1901e+00,\n",
      "        -5.8223e-01,  1.0728e+00,  3.5865e-01,  4.2351e-01, -5.6954e-01,\n",
      "        -8.5222e-01, -9.3196e-01, -6.9479e-01, -1.0820e+00, -5.2760e-01,\n",
      "        -8.6313e-01, -8.6442e-01,  1.6214e-01, -7.6223e-01, -3.0522e-01,\n",
      "         2.0889e-01,  1.7105e-01, -5.8668e-01, -7.8614e-01, -1.6590e-01,\n",
      "        -2.2922e-01,  7.6972e-01, -2.9553e-01,  1.0000e+00,  1.0192e-01,\n",
      "        -1.0229e-01, -2.7340e-01, -4.6597e-01,  7.0842e-01, -6.6384e-01,\n",
      "        -5.1198e-01, -6.9132e-01, -9.2252e-01,  5.6327e-01, -8.0773e-01,\n",
      "        -7.3454e-01, -4.6876e-01,  4.7758e-01, -5.2074e-02,  6.4325e-01,\n",
      "        -1.0025e+00,  7.4789e-01, -9.8580e-01, -6.1363e-01,  6.6589e-01,\n",
      "        -1.1749e+00, -6.9884e-01,  1.0465e+00, -1.9920e-01, -3.8599e-01,\n",
      "        -6.2273e-01, -8.2935e-01, -7.9309e-01, -1.2689e+00, -3.2974e-01,\n",
      "        -5.0878e-01, -8.6923e-01, -9.4125e-01, -6.3415e-01, -1.2358e+00,\n",
      "        -7.0380e-01,  2.7919e-01, -1.0160e+00,  2.9928e-01, -8.4400e-01,\n",
      "        -8.3064e-01, -9.0498e-01, -2.2070e-01, -1.1601e+00,  3.1661e-01,\n",
      "        -1.3671e+00,  5.0174e-01, -4.1611e-01, -1.9844e-01, -7.1928e-01,\n",
      "        -3.6111e-01, -8.7884e-01, -5.7047e-01, -4.9899e-01, -1.0670e+00,\n",
      "        -6.5430e-01, -6.8204e-01, -1.1673e+00,  8.0272e-01,  9.0036e-02,\n",
      "        -1.4400e+00,  2.9176e-01, -8.9749e-01, -6.7548e-01, -9.3913e-01,\n",
      "        -6.4014e-01,  8.7563e-01, -9.0269e-02, -1.8495e-01,  6.8408e-01,\n",
      "        -9.9054e-01, -4.7816e-01, -7.0488e-01, -4.5079e-01, -1.4490e-01,\n",
      "         5.8515e-01, -8.6970e-02, -6.2257e-01, -4.5183e-01,  1.0062e+00,\n",
      "        -8.6692e-01, -5.6137e-01,  1.6995e+00, -2.5570e-01,  1.0390e+00,\n",
      "        -1.0809e+00, -1.3396e+00, -8.2565e-01, -3.9317e-01, -4.0768e-01,\n",
      "        -7.7541e-01, -4.3306e-01,  7.1105e-01, -1.1624e+00,  1.0518e+00,\n",
      "        -8.0386e-01, -1.5669e-01, -6.2096e-01, -6.3850e-01, -2.7510e-01,\n",
      "         9.1868e-01, -5.6608e-01, -7.4105e-01, -6.6120e-01, -5.0306e-01,\n",
      "        -1.9951e-01, -9.9964e-01, -4.9497e-01,  3.6573e-01, -5.3219e-01,\n",
      "        -1.2454e-01,  6.0667e-01,  1.1040e+00, -4.9112e-01, -6.8293e-01,\n",
      "        -7.3088e-01,  9.2730e-01, -9.3933e-01, -1.0117e+00, -4.6640e-01,\n",
      "        -8.6700e-01, -1.3305e+00, -5.6797e-01, -1.5559e-04, -7.6136e-01,\n",
      "        -5.3700e-01, -8.6403e-01, -5.6233e-01, -7.6115e-01, -1.0163e-01,\n",
      "        -7.9931e-01, -8.7818e-02, -6.4648e-01,  1.3215e+00, -1.0346e+00,\n",
      "         9.9492e-01, -7.8282e-01, -1.0069e+00, -8.3604e-01, -4.4964e-01,\n",
      "        -3.8046e-01, -7.2048e-01], device='cuda:0', requires_grad=True)\n",
      "[-4.39063519e-01  4.78624068e-02 -1.16800034e+00 -1.38864219e+00\n",
      " -5.37702560e-01 -3.28092039e-01  1.05086148e+00 -4.44011718e-01\n",
      " -7.24519789e-01 -3.23318183e-01 -9.36791062e-01 -7.66667426e-01\n",
      " -7.80825019e-01 -1.15975606e+00 -9.92734075e-01 -1.18657720e+00\n",
      " -4.99760062e-01 -1.40723035e-01 -6.77470863e-01 -6.71734214e-01\n",
      " -1.08811498e+00 -8.04751068e-02 -6.29625738e-01 -1.32312667e+00\n",
      " -6.49584174e-01 -1.08068597e+00 -1.98819742e-01 -9.70286906e-01\n",
      " -6.61123931e-01 -9.41344559e-01 -3.97154957e-01 -1.62735075e-01\n",
      " -3.12581241e-01  9.77702260e-01  1.53712511e-01  2.80201912e-01\n",
      " -7.79314935e-01 -5.49247980e-01  1.62571406e+00 -2.74468184e-01\n",
      " -1.85227346e+00 -4.03751343e-01 -6.01609111e-01 -4.40849751e-01\n",
      " -1.10144520e+00 -4.36659276e-01  2.39026800e-01 -8.74250591e-01\n",
      " -1.19005084e+00 -5.18214822e-01 -7.74056554e-01 -1.09636879e+00\n",
      " -7.08718777e-01  5.95682440e-03 -2.69343734e-01  2.16987565e-01\n",
      " -8.30178261e-01 -4.21437025e-01 -5.75524449e-01 -7.29299545e-01\n",
      " -2.23196670e-01 -7.63214290e-01 -1.01700974e+00 -8.71266663e-01\n",
      " -3.39610636e-01 -8.32076430e-01 -8.16406488e-01  1.09621954e+00\n",
      "  1.77970839e+00  1.83757293e+00 -2.91124970e-01  4.35349673e-01\n",
      " -9.84768927e-01  7.72291720e-01 -2.96838105e-01 -9.87077773e-01\n",
      " -2.46068940e-01 -7.34212399e-01  1.70739561e-01 -8.16442013e-01\n",
      " -7.46582508e-01 -5.33432484e-01  2.01735282e+00  5.19823842e-03\n",
      " -3.06358844e-01 -2.30991915e-01  5.09885192e-01 -7.54941165e-01\n",
      " -6.05298519e-01  4.29694086e-01 -3.80057573e-01  1.00048137e+00\n",
      " -9.32678521e-01  8.83097827e-01  1.27544582e-01 -8.16160500e-01\n",
      "  6.06198370e-01 -4.98278111e-01  1.23821937e-01 -2.67178506e-01\n",
      " -3.92767698e-01 -4.03511614e-01 -7.80994058e-01 -1.28272545e+00\n",
      " -7.26495028e-01  5.45630038e-01 -8.33071768e-01 -7.79255688e-01\n",
      " -2.12502718e-01  6.50089860e-01  1.83354342e+00 -7.42902040e-01\n",
      " -3.42016369e-01 -5.10861635e-01 -1.06630814e+00 -1.51322377e+00\n",
      " -3.53683025e-01 -7.62934387e-01 -6.28161311e-01 -1.89999834e-01\n",
      " -6.83902919e-01 -3.01777929e-01 -8.25131595e-01 -5.64257085e-01\n",
      " -4.74211514e-01 -8.57160211e-01 -1.30304837e+00  9.58647430e-01\n",
      "  5.54278910e-01 -8.29195917e-01 -9.56238329e-01 -1.01769793e+00\n",
      "  4.63390082e-01 -7.51437366e-01 -1.12463224e+00 -7.16390193e-01\n",
      "  1.71484388e-02 -9.83636022e-01 -1.84527189e-01  6.03900589e-02\n",
      "  2.01979339e-01 -4.47120629e-02  2.50727087e-01 -7.42183402e-02\n",
      " -6.65774345e-01  8.59097183e-01 -2.14231893e-01  6.88523591e-01\n",
      " -5.06402850e-01 -6.30886674e-01 -1.96289569e-01  4.38208908e-01\n",
      "  8.56648743e-01  5.93125105e-01  1.14473140e+00 -9.61944044e-01\n",
      "  8.55716765e-01 -6.64284408e-01 -3.51369947e-01 -3.60530019e-01\n",
      " -8.44576478e-01 -9.34138894e-01  9.59053516e-01  1.87857270e+00\n",
      "  8.33788335e-01 -7.66974092e-01 -1.12357044e+00 -4.89479959e-01\n",
      " -4.27101672e-01 -8.33794057e-01 -1.17835200e+00 -7.06959248e-01\n",
      "  9.64336991e-01 -1.06331885e+00 -1.06584775e+00 -7.84209609e-01\n",
      "  3.05860311e-01 -6.27693951e-01 -7.66919613e-01 -3.02072406e-01\n",
      "  5.98972961e-02 -4.50035244e-01  5.86051702e-01 -1.39921463e+00\n",
      "  1.61110604e+00 -1.15686333e+00 -8.53663623e-01 -1.38124335e+00\n",
      " -1.14540446e+00 -4.72907603e-01 -8.41928303e-01 -1.12316406e+00\n",
      " -1.15817988e+00 -9.41633046e-01 -1.44519138e+00 -1.43105583e-02\n",
      " -1.33912534e-01 -8.53915632e-01 -3.27290475e-01 -1.93438306e-01\n",
      " -7.83147514e-02 -7.72130340e-02 -1.05019462e+00 -6.39307918e-03\n",
      "  5.02786756e-01 -7.98868775e-01 -4.57901269e-01 -7.98564255e-01\n",
      " -1.24125087e+00 -7.75345743e-01 -8.13583851e-01 -6.44709468e-02\n",
      "  7.78882980e-01 -5.75559974e-01 -3.83600563e-01  4.39660288e-02\n",
      " -3.34513962e-01 -6.81062102e-01 -9.76988792e-01  4.85807925e-01\n",
      " -4.75215465e-01 -6.25946879e-01 -8.01309109e-01 -9.31522429e-01\n",
      " -8.23702931e-01 -8.49713564e-01  2.57319715e-02 -5.05790889e-01\n",
      " -1.23709774e+00  9.10780132e-02 -6.41425312e-01  1.43529487e+00\n",
      " -1.28963947e-01 -4.57170665e-01 -5.33572972e-01  1.63565242e+00\n",
      "  4.90108132e-01 -1.10342705e+00 -5.44211864e-01  1.62165844e+00\n",
      " -3.32949966e-01  1.47434247e+00 -1.26677001e+00 -1.51425588e+00\n",
      " -6.99484527e-01 -9.32500660e-01 -9.25801635e-01  8.28346789e-01\n",
      " -8.69744003e-01 -6.68884695e-01 -1.08570743e+00 -6.41387701e-01\n",
      " -8.70555162e-01 -9.35997784e-01  1.22073615e+00  1.66247010e-01\n",
      " -3.09744596e-01 -9.08894956e-01 -1.46388149e+00 -8.62480342e-01\n",
      " -7.43947327e-02  1.26090169e+00 -5.83728492e-01 -3.30571979e-02\n",
      "  9.63629708e-02 -6.50845289e-01 -1.07993925e+00 -5.15374422e-01\n",
      " -6.77122951e-01 -4.23951983e-01 -1.07894719e+00  1.12016737e+00\n",
      " -8.52889121e-01 -9.95824635e-01 -7.28076696e-01  7.72615552e-01\n",
      " -7.67617166e-01 -1.45766747e+00 -6.16439342e-01 -5.99994540e-01\n",
      " -1.02248204e+00 -1.16004038e+00 -6.88214242e-01  6.05508536e-02\n",
      " -9.35664415e-01 -6.95412517e-01 -2.38968924e-01 -6.58665717e-01\n",
      "  1.20605850e+00  7.83790171e-01 -7.33327687e-01 -8.16817701e-01\n",
      " -1.29770911e+00  1.29790950e+00 -6.44349992e-01 -1.19578116e-01\n",
      "  1.26680064e+00 -8.67452860e-01 -6.24230266e-01 -5.54192126e-01\n",
      "  5.95954239e-01 -5.20417392e-02  9.83642817e-01 -9.88342345e-01\n",
      " -9.36274469e-01 -1.20833778e+00 -8.76367211e-01  7.82583714e-01\n",
      "  1.45418979e-02  8.78176093e-01 -4.46840376e-01  3.54318433e-02\n",
      " -3.76211107e-01 -6.53435111e-01 -1.02109337e+00  2.43720740e-01\n",
      " -1.06602335e+00 -3.79480809e-01 -1.93096772e-01 -9.17254388e-01\n",
      " -5.62801898e-01  8.90851736e-01 -6.26288772e-01 -6.72445834e-01\n",
      " -7.72912085e-01 -2.29794711e-01  8.06850255e-01 -4.94202405e-01\n",
      " -7.52266109e-01 -6.16675079e-01 -1.53365403e-01 -3.76934409e-01\n",
      " -1.23834789e+00 -3.11092108e-01 -1.18111408e+00 -7.67940402e-01\n",
      " -8.80063176e-01 -1.33928984e-01  1.09978485e+00 -7.04042733e-01\n",
      "  4.99560416e-01 -1.19822752e+00 -5.20512223e-01 -9.27282512e-01\n",
      " -1.19008112e+00 -5.82230389e-01  1.07282245e+00  3.58653605e-01\n",
      "  4.23513681e-01 -5.69543183e-01 -8.52219522e-01 -9.31958497e-01\n",
      " -6.94785535e-01 -1.08203697e+00 -5.27604401e-01 -8.63134027e-01\n",
      " -8.64423692e-01  1.62139893e-01 -7.62234867e-01 -3.05222422e-01\n",
      "  2.08885744e-01  1.71050966e-01 -5.86682320e-01 -7.86137462e-01\n",
      " -1.65903747e-01 -2.29215682e-01  7.69722402e-01 -2.95526087e-01\n",
      "  1.00002646e+00  1.01922400e-01 -1.02287546e-01 -2.73398459e-01\n",
      " -4.65965778e-01  7.08419263e-01 -6.63843751e-01 -5.11981547e-01\n",
      " -6.91320360e-01 -9.22523081e-01  5.63266218e-01 -8.07727814e-01\n",
      " -7.34537005e-01 -4.68762517e-01  4.77576673e-01 -5.20743094e-02\n",
      "  6.43250585e-01 -1.00251532e+00  7.47889996e-01 -9.85798597e-01\n",
      " -6.13627017e-01  6.65889859e-01 -1.17486155e+00 -6.98838294e-01\n",
      "  1.04651165e+00 -1.99203327e-01 -3.85986269e-01 -6.22732878e-01\n",
      " -8.29354644e-01 -7.93093741e-01 -1.26890635e+00 -3.29740793e-01\n",
      " -5.08781850e-01 -8.69227111e-01 -9.41246271e-01 -6.34151042e-01\n",
      " -1.23581195e+00 -7.03798473e-01  2.79188991e-01 -1.01604939e+00\n",
      "  2.99280524e-01 -8.44002843e-01 -8.30641091e-01 -9.04982448e-01\n",
      " -2.20698223e-01 -1.16013789e+00  3.16606820e-01 -1.36712921e+00\n",
      "  5.01737177e-01 -4.16107923e-01 -1.98442236e-01 -7.19283044e-01\n",
      " -3.61108452e-01 -8.78835142e-01 -5.70466101e-01 -4.98991638e-01\n",
      " -1.06698716e+00 -6.54296219e-01 -6.82044089e-01 -1.16727054e+00\n",
      "  8.02720249e-01  9.00357962e-02 -1.43998182e+00  2.91758209e-01\n",
      " -8.97488892e-01 -6.75479710e-01 -9.39133525e-01 -6.40144408e-01\n",
      "  8.75629187e-01 -9.02691334e-02 -1.84947357e-01  6.84076488e-01\n",
      " -9.90541041e-01 -4.78155762e-01 -7.04882622e-01 -4.50790137e-01\n",
      " -1.44900486e-01  5.85148454e-01 -8.69703069e-02 -6.22574508e-01\n",
      " -4.51825082e-01  1.00616658e+00 -8.66923928e-01 -5.61366677e-01\n",
      "  1.69948959e+00 -2.55698562e-01  1.03898191e+00 -1.08086741e+00\n",
      " -1.33958125e+00 -8.25649440e-01 -3.93170685e-01 -4.07681376e-01\n",
      " -7.75406301e-01 -4.33059126e-01  7.11052537e-01 -1.16243768e+00\n",
      "  1.05176902e+00 -8.03860545e-01 -1.56687200e-01 -6.20963633e-01\n",
      " -6.38496637e-01 -2.75095463e-01  9.18677330e-01 -5.66077054e-01\n",
      " -7.41053283e-01 -6.61196709e-01 -5.03062367e-01 -1.99513063e-01\n",
      " -9.99639630e-01 -4.94967639e-01  3.65729839e-01 -5.32185793e-01\n",
      " -1.24537848e-01  6.06671810e-01  1.10400093e+00 -4.91121739e-01\n",
      " -6.82927668e-01 -7.30883956e-01  9.27299500e-01 -9.39329922e-01\n",
      " -1.01169825e+00 -4.66402054e-01 -8.66996467e-01 -1.33051348e+00\n",
      " -5.67972720e-01 -1.55592919e-04 -7.61357963e-01 -5.37004948e-01\n",
      " -8.64027143e-01 -5.62328398e-01 -7.61154354e-01 -1.01625107e-01\n",
      " -7.99310684e-01 -8.78184065e-02 -6.46484017e-01  1.32151449e+00\n",
      " -1.03464878e+00  9.94916975e-01 -7.82817066e-01 -1.00694382e+00\n",
      " -8.36038589e-01 -4.49639827e-01 -3.80458236e-01 -7.20481515e-01]\n",
      "Encoder1.weight Encoder1_w0\n",
      "(172032,)\n",
      "torch.Size([512, 336])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0749, -0.0369, -0.0309,  ..., -0.0184,  0.0093,  0.0648],\n",
      "        [ 0.0566, -0.0327, -0.0441,  ..., -0.0904, -0.0137, -0.0701],\n",
      "        [-0.0557, -0.0615,  0.0332,  ..., -0.0514, -0.0148, -0.0015],\n",
      "        ...,\n",
      "        [ 0.0429, -0.0666, -0.0625,  ..., -0.1661,  0.2204, -0.0098],\n",
      "        [-0.0430,  0.0243,  0.0069,  ..., -0.0329,  0.0024,  0.0509],\n",
      "        [-0.0559, -0.0146,  0.0019,  ..., -0.0258,  0.0226, -0.0403]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "[ 0.07493064 -0.03687882 -0.03090668 ... -0.02584585  0.02256128\n",
      " -0.04030594]\n",
      "Encoder1.bias Encoder1_b0\n",
      "(512,)\n",
      "torch.Size([512])\n",
      "Parameter containing:\n",
      "tensor([-0.8888, -1.0076, -0.9453, -1.1037, -0.9275, -0.8630, -0.8056, -0.8400,\n",
      "        -1.0474, -0.9582, -1.1243, -0.7306, -1.0330, -1.0848, -0.9526, -1.0446,\n",
      "        -0.8230, -1.0557, -0.7865, -0.7681, -1.0364, -0.7908, -1.0357, -0.8983,\n",
      "        -0.8502, -0.7437, -0.8666, -0.8393, -1.1218, -1.0878, -0.9887, -0.7803,\n",
      "        -1.4398, -0.9827, -0.8727, -1.0343, -0.9160, -0.9059, -1.0915, -1.2934,\n",
      "        -0.9181, -0.8255, -1.0449, -0.9881, -0.7136, -0.7349, -0.8952, -1.0563,\n",
      "        -0.8364, -1.0057, -0.8321, -0.8928, -0.8484, -1.0322, -1.2118, -1.1346,\n",
      "        -0.9346, -0.9379, -1.0691, -0.9966, -1.0253, -0.9700, -0.8659, -0.8239,\n",
      "        -0.7564, -1.1317, -0.6116, -1.0400, -0.9048, -0.9694, -0.7313, -0.7587,\n",
      "        -1.0928, -0.9292, -0.8972, -1.0330, -0.9855, -0.9848, -1.0315, -0.9555,\n",
      "        -1.0273, -1.1015, -0.9820, -0.9014, -0.7002, -1.0407, -1.0059, -0.7879,\n",
      "        -1.0773, -0.4498, -0.6656, -0.9709, -0.8627, -0.8778, -1.0444, -0.7572,\n",
      "        -0.8143, -1.2128, -0.9560, -1.0396, -1.1574, -0.8249, -0.9399, -1.0542,\n",
      "        -1.0823, -0.9553, -1.0058, -0.8866, -0.9373, -0.6494, -0.9181, -0.9803,\n",
      "        -0.7310, -0.8678, -1.0007, -0.9009, -1.1021, -0.1258, -0.8575, -0.8617,\n",
      "        -0.8220, -0.9378, -1.0890, -0.8330, -0.9790, -0.7850, -0.3375, -0.9433,\n",
      "        -0.6696, -0.7704, -0.8227, -0.8900, -0.7431, -1.2360, -0.8915, -0.9224,\n",
      "        -1.0594, -0.7549, -0.7711, -1.0445, -0.6866, -1.0305, -0.7601, -0.8989,\n",
      "        -0.6484, -1.0058, -1.0404, -1.0204, -1.0670, -1.0908, -1.0506, -0.6865,\n",
      "        -0.9991, -1.0376, -0.8119, -0.9682, -0.7175, -0.9248, -0.8482, -1.0869,\n",
      "        -1.0335, -0.9436, -0.9217, -1.0773, -0.6050, -1.1362, -0.7659, -0.9179,\n",
      "        -0.9544, -0.6986, -0.7307, -0.7837, -1.0532, -1.0450, -1.2055, -1.2261,\n",
      "        -0.8374, -1.1098, -0.8356, -0.8852, -0.8766, -1.0188, -1.1296, -1.0711,\n",
      "        -1.1192, -0.9496, -1.1673, -0.9768, -0.9827, -0.8963, -0.8340, -0.8625,\n",
      "        -0.7848, -0.8586, -0.7954, -1.0133, -0.8634, -0.9060, -1.1970, -0.8967,\n",
      "        -0.9998, -1.1654, -0.7689, -0.7758, -1.0857, -0.9619, -1.0237, -0.9397,\n",
      "        -0.7436, -0.6887, -0.9336, -0.9066, -0.7518, -0.9698, -0.8845, -0.7623,\n",
      "        -1.4690, -1.1430, -1.1195, -1.0151, -0.8141, -0.8812, -0.6365, -0.7073,\n",
      "        -0.7594, -0.9350, -0.9947, -0.8825, -0.8539, -0.9112, -1.0258, -1.1078,\n",
      "        -0.8958, -0.8308, -0.9671, -0.8310, -1.1104, -0.8286, -1.0262, -0.7728,\n",
      "        -0.8146, -0.7374, -1.1970, -1.0823, -1.1032, -0.8836, -0.7582, -0.9844,\n",
      "        -1.1346, -0.9427, -0.9012, -0.8724, -0.6528, -0.7799, -1.0050, -1.0491,\n",
      "        -0.9489, -1.1249, -0.5613, -1.0079, -0.8735, -1.1313, -1.0967, -1.0333,\n",
      "        -0.8021, -1.0462, -1.1164, -0.9150, -0.9814, -1.0445, -1.0262, -0.8249,\n",
      "        -1.1222, -1.1237, -1.2142, -0.8908, -1.0601, -0.8540, -0.9588, -0.9731,\n",
      "        -0.9826, -1.2438, -1.0067, -0.9847, -0.9780, -1.7346, -0.9803, -1.0015,\n",
      "        -0.8705, -1.2836, -1.0138, -0.8688, -1.1646, -1.0499, -0.4535, -0.9389,\n",
      "        -0.8371, -0.8127, -1.0697, -0.9084, -1.0771, -1.0756, -0.8713, -0.8277,\n",
      "        -1.0469, -0.9485, -1.0311, -0.8313, -0.9378, -0.9846, -0.8931, -0.9728,\n",
      "        -0.9004, -1.0419, -0.8654, -1.0742, -0.8859, -0.9309, -1.1415, -0.9094,\n",
      "        -1.5257, -0.8559, -0.7822, -1.0267, -0.7765, -0.8622, -0.9703, -0.7295,\n",
      "        -1.0836, -0.7406, -0.8620, -0.7737, -1.0271, -0.5674, -0.7836, -0.8377,\n",
      "        -0.7316, -0.5626, -0.7518, -0.9961, -0.9958, -0.9959, -0.7538, -1.0824,\n",
      "        -0.9866, -0.8271, -0.9531, -0.9728, -0.8510, -0.8145, -0.7969, -0.8666,\n",
      "        -0.8561, -0.8437, -0.9830, -1.1277, -0.6824, -0.9183, -0.7992, -0.4922,\n",
      "        -0.7682, -0.5790, -0.8403, -0.9242, -0.9469, -1.1167, -0.6529, -0.8533,\n",
      "        -1.0876, -0.8777, -0.9963, -0.7336, -1.0545, -1.1081, -0.8628, -0.6950,\n",
      "        -1.1514, -0.6708, -0.9038, -0.8336, -1.0233, -0.8313, -1.0695, -0.8986,\n",
      "        -0.7910, -0.8355, -1.0823, -1.0193, -0.7091, -0.9027, -0.6446, -0.6524,\n",
      "        -0.7964, -1.0699, -0.9329, -0.6908, -1.0075, -0.7816, -1.3074, -0.8876,\n",
      "        -0.6870, -1.0474, -0.5319, -1.1477, -0.9085, -1.0794, -1.0510, -0.8662,\n",
      "        -0.8437, -0.9579, -0.9231, -0.7004, -0.8112, -0.8163, -0.8340, -0.9590,\n",
      "        -0.5366, -0.8549, -0.8262, -0.8646, -1.1485, -0.9203, -0.7185, -0.9567,\n",
      "        -1.1508, -1.2308, -0.8046, -1.1062, -0.9151, -0.9427, -1.0795, -0.9024,\n",
      "        -0.6809, -0.6924, -0.8688, -0.8941, -1.0438, -1.3090, -1.0683, -0.8500,\n",
      "        -0.8167, -0.7334, -0.7048, -1.0177, -0.8901, -0.9481, -0.8522, -1.0359,\n",
      "        -0.9960, -1.1091, -0.8363, -0.9793, -1.0408, -1.0166, -0.9180, -0.9616,\n",
      "        -0.9228, -0.9110, -1.0107, -0.7788, -1.0881, -0.8158, -0.9736, -1.0743,\n",
      "        -0.9659, -0.7809, -0.8382, -0.5700, -1.0982, -0.6111, -0.8258, -0.7070,\n",
      "        -0.9963, -1.0094, -0.6633, -0.9072, -1.0403, -0.8184, -0.5978, -0.9522,\n",
      "        -0.7683, -0.8101, -1.0779, -0.7848, -1.1047, -1.0643, -1.0619, -0.9517,\n",
      "        -1.0518, -1.0823, -0.8650, -0.8105, -0.7492, -0.8736, -0.5541, -0.9405,\n",
      "        -0.7980, -0.7885, -0.9775, -0.7233, -1.1002, -0.8389, -0.8596, -0.9720,\n",
      "        -0.9944, -0.9795, -1.0157, -0.9656, -1.0747, -0.9373, -0.9533, -1.3089],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "[-0.88878864 -1.0076454  -0.94534403 -1.1036823  -0.9274636  -0.8629959\n",
      " -0.80561405 -0.84004146 -1.047427   -0.95821494 -1.1243284  -0.7305571\n",
      " -1.0329735  -1.0848497  -0.95257705 -1.044601   -0.8229793  -1.0556929\n",
      " -0.7865051  -0.76809514 -1.0363717  -0.7908018  -1.0357327  -0.8982753\n",
      " -0.85024905 -0.74371564 -0.8666013  -0.839259   -1.1218426  -1.0878146\n",
      " -0.98866343 -0.7803016  -1.4398189  -0.9826766  -0.8727192  -1.0342684\n",
      " -0.916024   -0.90591115 -1.0914595  -1.2933786  -0.91809183 -0.8255458\n",
      " -1.0448813  -0.9880676  -0.71358    -0.7349236  -0.8952408  -1.0563027\n",
      " -0.8364104  -1.005693   -0.83208036 -0.89284647 -0.84842426 -1.032188\n",
      " -1.2117606  -1.1345633  -0.93458986 -0.93792003 -1.0691113  -0.9965681\n",
      " -1.0252908  -0.9700064  -0.8658568  -0.82392013 -0.7563567  -1.1317025\n",
      " -0.61163384 -1.0400307  -0.9048203  -0.9694216  -0.731304   -0.7587049\n",
      " -1.0928183  -0.92924994 -0.8971621  -1.0330468  -0.9854791  -0.98475176\n",
      " -1.0314672  -0.9555276  -1.0272543  -1.1014606  -0.98204094 -0.9014223\n",
      " -0.7002192  -1.0407089  -1.0059476  -0.7879212  -1.077303   -0.44979614\n",
      " -0.66558635 -0.97093326 -0.8626875  -0.877757   -1.0443703  -0.75724113\n",
      " -0.8142713  -1.2128087  -0.95603395 -1.0396303  -1.1573988  -0.82494414\n",
      " -0.93989277 -1.0541679  -1.0822988  -0.95528847 -1.0058141  -0.8866192\n",
      " -0.9372991  -0.64940727 -0.91811377 -0.98028284 -0.7309683  -0.86783594\n",
      " -1.0007486  -0.90091974 -1.1020849  -0.12576348 -0.8575384  -0.86171234\n",
      " -0.8219911  -0.9378271  -1.0890177  -0.8330439  -0.97900534 -0.78498954\n",
      " -0.33750263 -0.9433041  -0.66955894 -0.77039653 -0.8227486  -0.8900219\n",
      " -0.74313045 -1.236042   -0.8914787  -0.9223789  -1.0593941  -0.75492454\n",
      " -0.7710996  -1.044519   -0.6865579  -1.030503   -0.76013905 -0.8989377\n",
      " -0.6484255  -1.0057765  -1.0404077  -1.0203744  -1.066961   -1.0907848\n",
      " -1.0505829  -0.68650186 -0.99910146 -1.0375656  -0.8118944  -0.96819943\n",
      " -0.7174682  -0.9247907  -0.84818435 -1.0869119  -1.0335262  -0.94355047\n",
      " -0.92173755 -1.0773451  -0.6049823  -1.1362382  -0.76587087 -0.9179173\n",
      " -0.9543745  -0.69860053 -0.73071843 -0.78374904 -1.0532118  -1.0450306\n",
      " -1.2055395  -1.2260942  -0.83736825 -1.1098424  -0.83555293 -0.88515353\n",
      " -0.87663543 -1.0188032  -1.129636   -1.0710888  -1.1191688  -0.94964826\n",
      " -1.1673361  -0.9768318  -0.98271513 -0.8962853  -0.83403456 -0.8625154\n",
      " -0.78482807 -0.85858154 -0.7953996  -1.0132589  -0.86342764 -0.90600955\n",
      " -1.1969815  -0.89674324 -0.99983615 -1.1653827  -0.76890785 -0.77583355\n",
      " -1.0856518  -0.9618539  -1.0237058  -0.9397107  -0.7435925  -0.6886922\n",
      " -0.93362397 -0.90662014 -0.7518013  -0.9698012  -0.8844799  -0.7622695\n",
      " -1.4689701  -1.1429653  -1.1194837  -1.0150902  -0.8140822  -0.88120836\n",
      " -0.6365328  -0.70732963 -0.7593869  -0.93497086 -0.9946572  -0.88251466\n",
      " -0.8539073  -0.9111528  -1.025847   -1.107822   -0.89579844 -0.8307818\n",
      " -0.96714807 -0.8309787  -1.1103879  -0.82863235 -1.0262204  -0.7727762\n",
      " -0.81461793 -0.73743165 -1.1969821  -1.082344   -1.103249   -0.88357747\n",
      " -0.7582318  -0.98437804 -1.1345953  -0.9426746  -0.90117824 -0.87241066\n",
      " -0.65278894 -0.7799242  -1.0049975  -1.0491248  -0.94887596 -1.1249092\n",
      " -0.5612691  -1.0079095  -0.87350637 -1.1312692  -1.0967114  -1.0332878\n",
      " -0.80206865 -1.0462047  -1.116356   -0.9150447  -0.9814343  -1.0444708\n",
      " -1.0261633  -0.82493454 -1.1222486  -1.1237222  -1.2142292  -0.89081293\n",
      " -1.0600642  -0.8540127  -0.95879805 -0.9730536  -0.9825568  -1.2438339\n",
      " -1.006655   -0.9847208  -0.9780141  -1.7346425  -0.9803263  -1.0015098\n",
      " -0.87053794 -1.2835829  -1.013808   -0.8688491  -1.1646441  -1.0498947\n",
      " -0.453492   -0.93890005 -0.83712    -0.8127109  -1.069742   -0.90842855\n",
      " -1.0770798  -1.0755867  -0.871278   -0.82768834 -1.0468878  -0.94847405\n",
      " -1.0311002  -0.8313304  -0.93778247 -0.9846392  -0.89307153 -0.9728012\n",
      " -0.90037185 -1.0418851  -0.865407   -1.0742214  -0.88588345 -0.93088055\n",
      " -1.1414834  -0.9093783  -1.5256666  -0.85589755 -0.7821815  -1.0266899\n",
      " -0.77650785 -0.86218655 -0.9703019  -0.72948045 -1.0836034  -0.7405547\n",
      " -0.8620236  -0.7737067  -1.0270805  -0.567449   -0.7836481  -0.83774894\n",
      " -0.73156804 -0.56256056 -0.7517805  -0.9961189  -0.995784   -0.9958529\n",
      " -0.75382006 -1.0823841  -0.98664    -0.82710326 -0.9530936  -0.9727988\n",
      " -0.85102904 -0.8145015  -0.79694736 -0.86663187 -0.85613984 -0.84366095\n",
      " -0.98300797 -1.1277136  -0.68239856 -0.9183309  -0.79919386 -0.49217564\n",
      " -0.76824003 -0.5790304  -0.8403411  -0.92419636 -0.9469462  -1.1166825\n",
      " -0.652871   -0.85327715 -1.0875536  -0.87769794 -0.99630445 -0.7336077\n",
      " -1.0544915  -1.1081152  -0.8627763  -0.69499403 -1.1513995  -0.6707538\n",
      " -0.9038431  -0.8335826  -1.0233376  -0.83130103 -1.0694873  -0.898568\n",
      " -0.7909605  -0.83545023 -1.0822527  -1.0192841  -0.7090752  -0.9026566\n",
      " -0.6445674  -0.6524148  -0.7964086  -1.0698544  -0.9329174  -0.69076157\n",
      " -1.0075238  -0.78155625 -1.3074131  -0.8876046  -0.6869864  -1.0474294\n",
      " -0.5318837  -1.1476591  -0.9085003  -1.0794045  -1.0509511  -0.8662175\n",
      " -0.84373915 -0.95791996 -0.92310333 -0.70039916 -0.81115115 -0.8162791\n",
      " -0.8339927  -0.95902085 -0.5366414  -0.85494244 -0.82615834 -0.8645843\n",
      " -1.1485105  -0.9202768  -0.71853316 -0.95668834 -1.1508154  -1.2307698\n",
      " -0.8045842  -1.106229   -0.9151368  -0.94268256 -1.0794784  -0.9023593\n",
      " -0.6809186  -0.6923797  -0.86879784 -0.8941137  -1.0438181  -1.3089807\n",
      " -1.0683197  -0.85003805 -0.81672335 -0.733378   -0.7047733  -1.0176657\n",
      " -0.8900584  -0.94813067 -0.8522337  -1.0358658  -0.9960142  -1.1090931\n",
      " -0.83630764 -0.97931993 -1.0407848  -1.0165703  -0.9180255  -0.96163094\n",
      " -0.9227631  -0.91097057 -1.0106878  -0.77879906 -1.0880865  -0.8157879\n",
      " -0.9736305  -1.074257   -0.9658551  -0.7809437  -0.838205   -0.56999177\n",
      " -1.098209   -0.6110573  -0.82577145 -0.7070175  -0.9962794  -1.0094229\n",
      " -0.6632673  -0.9071677  -1.0402743  -0.81840265 -0.59777266 -0.95223796\n",
      " -0.76826876 -0.8101111  -1.07787    -0.784804   -1.1047448  -1.0643266\n",
      " -1.0619017  -0.9516757  -1.0517995  -1.0823116  -0.8649774  -0.810465\n",
      " -0.7492162  -0.8736493  -0.5540857  -0.9405075  -0.79802215 -0.78850627\n",
      " -0.9775042  -0.72326237 -1.100171   -0.83887184 -0.8595862  -0.97198296\n",
      " -0.99439335 -0.9795191  -1.0157238  -0.9656294  -1.0746726  -0.9373051\n",
      " -0.95325184 -1.3089169 ]\n",
      "Encoder2.weight Encoder2_w0\n",
      "(932864,)\n",
      "torch.Size([512, 1822])\n",
      "Parameter containing:\n",
      "tensor([[-1.3361e-02, -1.7455e-02, -4.7904e-03,  ..., -9.7306e-02,\n",
      "         -4.4195e-02, -5.6793e-02],\n",
      "        [ 6.8297e-02, -4.4632e-02, -1.0952e-02,  ..., -8.5492e-02,\n",
      "          5.6882e-02, -5.4690e-03],\n",
      "        [ 1.0006e-01,  1.0777e-02, -2.3435e-02,  ...,  1.1194e-01,\n",
      "         -3.5329e-02, -8.3537e-02],\n",
      "        ...,\n",
      "        [ 6.4019e-02,  7.8077e-02,  6.8351e-02,  ...,  3.5796e-01,\n",
      "          5.5197e-02, -5.3764e-02],\n",
      "        [ 8.4693e-02,  1.2061e-01,  6.3433e-02,  ...,  1.4407e-01,\n",
      "         -1.2749e-02, -2.6650e-02],\n",
      "        [ 1.1588e-01,  1.0543e-01,  5.2695e-03,  ..., -4.5953e-02,\n",
      "         -8.6002e-05,  1.0513e-01]], device='cuda:0', requires_grad=True)\n",
      "[-1.3361306e-02 -1.7455259e-02 -4.7903904e-03 ... -4.5952864e-02\n",
      " -8.6001732e-05  1.0512610e-01]\n",
      "Encoder2.bias Encoder2_b0\n",
      "(512,)\n",
      "torch.Size([512])\n",
      "Parameter containing:\n",
      "tensor([-1.5927, -1.4015, -1.1201, -1.8844, -1.9497, -1.3667, -1.4710, -1.4563,\n",
      "        -1.1907, -0.9385, -1.4060, -1.5737, -1.4315, -1.0672, -1.7021, -0.9704,\n",
      "        -1.6149, -1.5217, -1.2934, -1.7769, -1.3949, -1.5239, -1.6150, -1.4001,\n",
      "        -1.4085, -1.3620, -1.9522, -1.9692, -1.5474, -1.4026, -1.1931, -0.5997,\n",
      "        -1.0898, -1.5129, -1.2172, -1.3592, -1.2393, -1.3468, -1.2688, -1.1243,\n",
      "        -1.3202, -1.4144, -1.5063, -1.3166, -1.2533, -1.4259,  0.3237, -1.1241,\n",
      "        -1.1292, -1.6249, -1.5221, -1.5608, -1.2509, -1.3242, -1.4866, -1.7007,\n",
      "        -1.0774, -1.3766, -1.6013, -1.0920, -1.0012, -1.3568, -1.6823, -1.4959,\n",
      "        -1.5220, -1.7318, -1.1582, -1.2673, -1.3256, -1.1628, -1.3145, -1.4582,\n",
      "        -1.5587, -1.4703, -1.1190, -1.5670, -1.6148, -1.4526, -1.2984, -1.4331,\n",
      "        -1.7149, -1.0494, -1.4660, -1.3035, -1.4282, -1.2627, -1.4415, -1.4562,\n",
      "        -1.0282, -1.7169, -1.6399, -0.7384, -1.2733, -1.6672, -1.6260, -1.2213,\n",
      "        -1.5575, -1.5151, -1.5493, -1.5480, -1.2572, -1.0622, -1.5120, -1.3660,\n",
      "        -0.9192, -1.6521, -1.2626, -1.5872, -1.0379, -1.2053, -1.6189, -1.6781,\n",
      "        -1.8070, -1.6824, -1.3032, -1.6219, -1.3047, -1.7215, -0.9563, -1.2035,\n",
      "        -1.5118, -1.5348, -1.6799, -1.4289, -1.8798, -0.7590, -1.3109, -1.1192,\n",
      "        -1.2521, -1.4328, -1.5419, -1.3113, -1.2943, -1.3574, -1.3348, -0.8675,\n",
      "        -1.2307, -1.4416, -1.2194, -1.4722, -1.4913, -1.3074, -1.1175, -0.9173,\n",
      "        -1.0153, -1.4328, -1.3417, -0.4013, -1.4231, -1.5359, -1.0053, -1.4289,\n",
      "        -1.5490, -1.1769, -1.6046, -1.2823, -1.8687, -1.4223, -1.3304, -1.3551,\n",
      "        -1.0711, -1.1524, -0.5180, -1.8593, -1.3777, -1.1464, -1.2811, -1.2308,\n",
      "        -1.3391, -1.5064, -1.5086, -0.3384, -1.3297, -1.7657, -1.5200, -1.4808,\n",
      "        -1.3787, -1.1307, -1.2956, -1.2300, -0.7137, -1.6403, -1.2833, -1.2609,\n",
      "        -1.2208, -1.0944, -1.4163, -1.4535, -1.7442, -1.1736, -1.4423, -0.7774,\n",
      "        -1.6892, -1.3148, -1.4443, -0.8369, -1.4366, -1.3776, -1.0446, -1.7209,\n",
      "        -1.6584, -1.4959, -1.4184, -1.2634, -1.6722, -1.2912, -1.6656, -1.6366,\n",
      "        -1.4101, -1.1486, -1.3220, -1.3758, -1.9152, -1.5024, -1.1129, -1.4169,\n",
      "        -1.2199, -1.2757, -1.4424, -1.2993, -1.3998, -1.8113, -1.8278, -1.8729,\n",
      "         0.5483, -1.0278, -1.5428, -1.3204, -0.9481, -1.7328, -1.5832, -1.5867,\n",
      "        -1.9324, -1.2838, -1.3105, -1.6723, -1.5227, -1.3714, -1.1755, -1.3142,\n",
      "        -1.5687, -1.7204, -1.5723, -1.5585, -0.9637, -1.3068, -1.3721, -1.5686,\n",
      "        -1.5802, -1.4024, -1.5671, -1.7383, -1.6320, -1.2363, -1.4999, -1.3201,\n",
      "        -1.4042, -1.3260, -0.9557, -1.7510, -1.4607, -1.3937, -0.7571, -1.4642,\n",
      "        -1.3227, -0.5073, -1.2402, -1.4242, -1.0634, -1.4925, -1.1722, -1.6921,\n",
      "        -1.8705, -1.5220, -1.4796, -1.3880, -1.4167, -1.3146, -1.3443, -1.0554,\n",
      "        -1.5916, -1.5723, -1.3658, -1.2239, -1.5555, -0.7871, -1.2475, -1.1572,\n",
      "        -1.4063, -1.4519, -0.9218, -1.5896, -1.6632, -1.9011, -1.0407, -1.4727,\n",
      "        -1.4411, -1.4091, -1.4154, -1.6117, -1.3345, -1.4853, -1.3506, -1.5172,\n",
      "        -1.5790, -1.6964, -1.0952, -1.3796, -0.9391, -1.1425, -1.2903, -1.3590,\n",
      "        -1.6289, -1.4314, -1.8317, -1.4496, -1.2959, -1.4025, -1.4165, -1.4939,\n",
      "        -0.9182, -0.4959, -0.3393, -1.3933, -0.9509, -1.3339, -0.9281, -1.0430,\n",
      "        -0.7114, -1.0609, -1.4282, -1.3717, -0.2411, -1.3362, -1.1925, -1.4284,\n",
      "        -1.7342, -1.2205, -1.4861, -1.2393, -1.3874, -0.3990, -1.2392, -1.3176,\n",
      "        -1.5699, -1.2425, -1.5035, -1.3737, -1.4493, -1.3290, -1.2039, -1.3805,\n",
      "        -1.2432, -1.0850, -1.3134, -1.4570, -1.2211, -1.5850, -1.6850, -1.5849,\n",
      "        -1.5255, -1.4872, -1.5271, -1.4773, -1.2564, -1.4447, -1.0700, -1.5707,\n",
      "        -1.3802, -1.7729, -1.7383, -1.2542, -1.3664, -1.2986, -1.5250, -1.2861,\n",
      "        -1.3444, -1.1481, -1.2283, -1.0738, -1.4314, -0.4766, -1.3161, -1.4990,\n",
      "        -1.1914, -1.4021, -1.2919, -1.2726, -0.1770, -1.3709, -1.5004, -1.6098,\n",
      "        -1.2890, -1.6665, -1.5052, -1.7415, -1.6479, -1.1088, -1.5413, -0.9684,\n",
      "        -0.2076, -1.4458, -1.6123, -1.6970, -1.4718, -1.6403, -1.5962, -1.4113,\n",
      "        -1.7102, -1.4563,  0.3793, -1.5889, -1.3262, -1.3859, -0.4609, -1.3226,\n",
      "        -1.4637, -1.3670, -1.4897, -1.3941, -1.4414, -1.6461, -1.4384, -1.3279,\n",
      "        -1.0757, -2.0033, -1.6206, -1.5272, -0.2803, -0.8975, -1.3095, -1.6226,\n",
      "        -1.2377, -1.4459, -1.6165, -1.1601, -1.1733, -1.6781, -1.6626, -1.3978,\n",
      "        -1.0958, -1.1901, -0.7517, -1.4023, -1.5251, -1.2098, -1.4678, -1.4356,\n",
      "        -1.4656, -1.1888, -1.2619, -1.7398, -1.5448, -1.5031, -1.3596, -1.0912,\n",
      "        -1.4630, -1.5091, -1.3720, -1.6804, -1.3007, -1.4108, -1.3724, -1.6002,\n",
      "        -1.4363, -1.6359, -1.5909, -1.7693, -1.5345, -1.1568, -1.4743, -1.3983,\n",
      "        -1.5622, -1.2929, -1.7790, -1.8617, -1.4979, -0.5016, -1.4051, -1.7093,\n",
      "        -1.5345, -1.2651, -1.9046, -1.6513, -1.5764, -1.8439, -1.5616, -1.3877,\n",
      "        -0.0642, -1.3873, -1.4258, -1.7834, -1.6602, -0.6489, -1.4892, -1.5114,\n",
      "        -1.4861, -1.3542, -1.2671, -1.5881, -1.5681, -0.9485, -0.7969, -1.6846,\n",
      "        -1.3999, -1.4649, -1.3012, -1.4593, -1.3316, -1.4484, -1.4714, -1.2102],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "[-1.5927038  -1.4014986  -1.1201179  -1.884351   -1.9497156  -1.3667129\n",
      " -1.4710414  -1.4563395  -1.1906669  -0.9385356  -1.4060248  -1.5737009\n",
      " -1.4315158  -1.0672218  -1.7020524  -0.9703568  -1.6149282  -1.5217398\n",
      " -1.293363   -1.7768892  -1.3949144  -1.5238825  -1.6149502  -1.4001327\n",
      " -1.4084609  -1.3620465  -1.9522245  -1.9691702  -1.5473771  -1.4025648\n",
      " -1.1930925  -0.59972304 -1.0897825  -1.5129157  -1.2171793  -1.3592336\n",
      " -1.2393291  -1.3468359  -1.2687541  -1.1243491  -1.3202084  -1.414422\n",
      " -1.5063232  -1.3165786  -1.2532843  -1.4258592   0.32371458 -1.1240784\n",
      " -1.1292285  -1.6249415  -1.5220535  -1.560796   -1.2508602  -1.3242271\n",
      " -1.4866283  -1.7006632  -1.0774189  -1.3766392  -1.6013483  -1.0919989\n",
      " -1.0011595  -1.3567698  -1.6822993  -1.4958559  -1.5220249  -1.7318407\n",
      " -1.1582361  -1.2673291  -1.3255633  -1.162761   -1.3144858  -1.4582416\n",
      " -1.5586629  -1.4703434  -1.1189657  -1.566965   -1.6147568  -1.4525986\n",
      " -1.2984266  -1.4330798  -1.7148591  -1.0494292  -1.4660363  -1.3035003\n",
      " -1.4281547  -1.2626925  -1.4415498  -1.4562213  -1.0281882  -1.7168877\n",
      " -1.6399099  -0.7384032  -1.2732589  -1.6671882  -1.625968   -1.2212996\n",
      " -1.5575261  -1.5151451  -1.5493127  -1.5480006  -1.257222   -1.0622038\n",
      " -1.5120271  -1.366028   -0.91917485 -1.6520823  -1.2625873  -1.5872476\n",
      " -1.0379317  -1.2052785  -1.618897   -1.6780541  -1.8070426  -1.6824182\n",
      " -1.3031671  -1.6218543  -1.3047279  -1.7214955  -0.9563485  -1.2035402\n",
      " -1.5117949  -1.5348231  -1.6799277  -1.4289243  -1.8798143  -0.75900096\n",
      " -1.3109008  -1.1192114  -1.252121   -1.4327501  -1.5418869  -1.3113205\n",
      " -1.294278   -1.3574332  -1.3347677  -0.86746925 -1.2307371  -1.4415504\n",
      " -1.2194281  -1.4722418  -1.4913334  -1.3073962  -1.1174748  -0.917295\n",
      " -1.0153131  -1.4327567  -1.3417429  -0.4012635  -1.4230804  -1.5358584\n",
      " -1.0052949  -1.4288995  -1.549049   -1.1769005  -1.6045729  -1.2823087\n",
      " -1.8686619  -1.4222857  -1.3304344  -1.355103   -1.0710596  -1.1523721\n",
      " -0.5180348  -1.8592538  -1.3777367  -1.1463834  -1.2811177  -1.2307799\n",
      " -1.3391476  -1.5063987  -1.5086237  -0.33836862 -1.3296825  -1.7656652\n",
      " -1.5199732  -1.480832   -1.378712   -1.1306833  -1.2956122  -1.2300022\n",
      " -0.7137042  -1.6402975  -1.2832938  -1.2609458  -1.2208476  -1.0943875\n",
      " -1.4163141  -1.4535416  -1.7442065  -1.1736288  -1.442339   -0.77741206\n",
      " -1.6891977  -1.3147631  -1.4443125  -0.83689123 -1.4366499  -1.3776307\n",
      " -1.0445757  -1.7208879  -1.6583916  -1.4958847  -1.4184389  -1.2633992\n",
      " -1.6721729  -1.2912053  -1.6655701  -1.6366422  -1.4101225  -1.1485872\n",
      " -1.3220303  -1.3758026  -1.9151839  -1.502424   -1.1128659  -1.4169471\n",
      " -1.2199287  -1.2756803  -1.442402   -1.2992536  -1.3998379  -1.8113354\n",
      " -1.8277962  -1.8728514   0.54828835 -1.0278424  -1.5428183  -1.320368\n",
      " -0.94808567 -1.7328095  -1.5831554  -1.5866965  -1.932369   -1.2838356\n",
      " -1.3104682  -1.6722937  -1.5226601  -1.3713874  -1.1755489  -1.3141918\n",
      " -1.5686598  -1.7204052  -1.5723227  -1.5585494  -0.96374106 -1.3068197\n",
      " -1.3721488  -1.568643   -1.5802283  -1.4023749  -1.5671102  -1.7382959\n",
      " -1.6319661  -1.236294   -1.4999415  -1.3201195  -1.4042364  -1.3259989\n",
      " -0.9557142  -1.7510113  -1.4606781  -1.3937037  -0.75714535 -1.4641773\n",
      " -1.3227459  -0.50730467 -1.240151   -1.4242353  -1.0633863  -1.492508\n",
      " -1.1722288  -1.6921307  -1.8704594  -1.5220112  -1.4796478  -1.388047\n",
      " -1.4167314  -1.314617   -1.3443483  -1.0553647  -1.5915723  -1.5723481\n",
      " -1.3657708  -1.2239428  -1.5555261  -0.787055   -1.2474661  -1.1572043\n",
      " -1.4063135  -1.4518696  -0.921781   -1.5896109  -1.6631502  -1.9011064\n",
      " -1.0407221  -1.4727436  -1.4410757  -1.409129   -1.4153563  -1.6116962\n",
      " -1.3344944  -1.4853421  -1.3506196  -1.5172464  -1.5789553  -1.6964158\n",
      " -1.095201   -1.3796449  -0.9391319  -1.1424568  -1.2902648  -1.3590387\n",
      " -1.6288521  -1.4314432  -1.8316898  -1.4495555  -1.2959089  -1.4025315\n",
      " -1.4165415  -1.4939421  -0.91822314 -0.49593565 -0.33927205 -1.3932537\n",
      " -0.9508848  -1.3339161  -0.92807025 -1.042975   -0.711421   -1.0609103\n",
      " -1.4281967  -1.3716688  -0.24113327 -1.3361832  -1.1925005  -1.4283631\n",
      " -1.7341522  -1.2204766  -1.4860913  -1.2392621  -1.3874217  -0.39902762\n",
      " -1.2392389  -1.3176069  -1.5699369  -1.2424788  -1.5034826  -1.3737252\n",
      " -1.4492973  -1.3289912  -1.2038814  -1.3804753  -1.2431722  -1.0850261\n",
      " -1.313351   -1.4569544  -1.2210692  -1.5850486  -1.6850315  -1.5849217\n",
      " -1.5255018  -1.4871529  -1.5270568  -1.4773437  -1.2564456  -1.4447334\n",
      " -1.0699965  -1.5706667  -1.3801796  -1.7729294  -1.7383301  -1.254216\n",
      " -1.366405   -1.2986315  -1.5249665  -1.2861063  -1.3444357  -1.1480567\n",
      " -1.2282828  -1.073785   -1.4314212  -0.4766325  -1.3161288  -1.4990402\n",
      " -1.191413   -1.4021115  -1.2919083  -1.2726113  -0.17696734 -1.3709321\n",
      " -1.5004003  -1.6097969  -1.288968   -1.6665459  -1.5052062  -1.741455\n",
      " -1.6478792  -1.1087561  -1.541335   -0.9684114  -0.2076094  -1.4457631\n",
      " -1.612274   -1.6969872  -1.4717726  -1.6402589  -1.5961835  -1.4112844\n",
      " -1.7101662  -1.4562764   0.37928197 -1.5889256  -1.3261665  -1.3858829\n",
      " -0.46091393 -1.322635   -1.463748   -1.3669786  -1.4896569  -1.3941175\n",
      " -1.4414425  -1.6461468  -1.4383727  -1.3278723  -1.0757222  -2.0032628\n",
      " -1.6205602  -1.527231   -0.28032082 -0.89750886 -1.3094928  -1.6225591\n",
      " -1.2377136  -1.4458696  -1.6164645  -1.1600811  -1.1732922  -1.6781126\n",
      " -1.6626132  -1.3978115  -1.0957992  -1.1901028  -0.7517059  -1.4023178\n",
      " -1.5251104  -1.209794   -1.4678186  -1.4356368  -1.4655578  -1.1887865\n",
      " -1.2618963  -1.7398474  -1.5447699  -1.503055   -1.3595692  -1.091226\n",
      " -1.4630415  -1.5091493  -1.3719668  -1.6804018  -1.3007482  -1.4107718\n",
      " -1.3724278  -1.600243   -1.4362714  -1.6358578  -1.5909127  -1.7693263\n",
      " -1.5345491  -1.1568345  -1.4742559  -1.3983483  -1.562238   -1.2929027\n",
      " -1.778999   -1.8616543  -1.4978569  -0.50160277 -1.4051191  -1.7093135\n",
      " -1.5344728  -1.2651201  -1.9046384  -1.6513367  -1.5763619  -1.8439074\n",
      " -1.5615546  -1.3877388  -0.06423842 -1.3872619  -1.4257727  -1.7834375\n",
      " -1.6602097  -0.64887923 -1.4892349  -1.511362   -1.4860795  -1.3542473\n",
      " -1.2670721  -1.5880833  -1.5680623  -0.94851184 -0.7968795  -1.6845908\n",
      " -1.3999143  -1.4649163  -1.3011853  -1.4592572  -1.3316218  -1.448367\n",
      " -1.4714344  -1.2102383 ]\n",
      "DenseRes0.FC0.weight DenseRes0_w0\n",
      "(2359296,)\n",
      "torch.Size([1536, 1536])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0090, -0.0363,  0.0320,  ...,  0.0125, -0.0421, -0.0202],\n",
      "        [ 0.0037,  0.0243, -0.0054,  ..., -0.0451, -0.0304, -0.0174],\n",
      "        [-0.0037, -0.0115, -0.1683,  ...,  0.0432,  0.0082, -0.0126],\n",
      "        ...,\n",
      "        [-0.0277,  0.0131, -0.0233,  ..., -0.1338,  0.0186, -0.1066],\n",
      "        [ 0.1042, -0.0179,  0.0643,  ...,  0.0136, -0.0786,  0.0380],\n",
      "        [-0.0545,  0.0669, -0.0514,  ...,  0.0671, -0.1717, -0.1112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "[ 0.00898107 -0.03626085  0.03200241 ...  0.06708694 -0.17169218\n",
      " -0.11116639]\n",
      "DenseRes0.FC0.bias DenseRes0_b0\n",
      "(1536,)\n",
      "torch.Size([1536])\n",
      "Parameter containing:\n",
      "tensor([-0.0294, -0.0458,  0.0791,  ..., -0.0211, -0.1323, -0.0643],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "[-0.02938156 -0.04577671  0.07912642 ... -0.02111363 -0.13231197\n",
      " -0.06432548]\n",
      "DenseRes0.FC1.weight DenseRes1_w0\n",
      "(2359296,)\n",
      "torch.Size([1536, 1536])\n",
      "Parameter containing:\n",
      "tensor([[-0.0240, -0.0419, -0.0106,  ..., -0.0550,  0.0624, -0.0773],\n",
      "        [ 0.0040, -0.0152,  0.0026,  ..., -0.1249,  0.0069, -0.0022],\n",
      "        [-0.0327,  0.0239, -0.2403,  ...,  0.0503, -0.1438, -0.0520],\n",
      "        ...,\n",
      "        [-0.0250, -0.0344, -0.1712,  ..., -0.2954, -0.0227,  0.1415],\n",
      "        [-0.0026, -0.0336,  0.0867,  ..., -0.0502, -0.4945,  0.1028],\n",
      "        [ 0.0280, -0.0271, -0.2191,  ..., -0.0514, -0.0389, -0.1367]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "[-0.02402146 -0.04194647 -0.01056417 ... -0.05136558 -0.03892693\n",
      " -0.13670921]\n",
      "DenseRes0.FC1.bias DenseRes1_b0\n",
      "(1536,)\n",
      "torch.Size([1536])\n",
      "Parameter containing:\n",
      "tensor([ 0.0734, -0.3294, -0.3978,  ..., -0.5254, -0.7873, -0.2056],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "[ 0.07337782 -0.32941338 -0.39784062 ... -0.5253885  -0.78731585\n",
      " -0.20560174]\n",
      "DenseRes1.FC0.weight DenseRes2_w0\n",
      "(2359296,)\n",
      "torch.Size([1536, 1536])\n",
      "Parameter containing:\n",
      "tensor([[-0.0762, -0.0660, -0.0273,  ...,  0.0266,  0.0362,  0.0253],\n",
      "        [-0.0124, -0.0978,  0.0200,  ...,  0.0414, -0.0138, -0.0253],\n",
      "        [-0.0267,  0.0024, -0.6002,  ...,  0.1154, -0.0468, -0.0547],\n",
      "        ...,\n",
      "        [ 0.0324, -0.0412, -0.0083,  ..., -0.1343,  0.0057, -0.0159],\n",
      "        [ 0.0303,  0.0665, -0.0051,  ...,  0.0098, -0.3463,  0.0044],\n",
      "        [-0.0065,  0.0246, -0.0161,  ..., -0.0527,  0.0030, -0.2432]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "[-0.07624074 -0.0659999  -0.02730457 ... -0.05274028  0.00304639\n",
      " -0.24319994]\n",
      "DenseRes1.FC0.bias DenseRes2_b0\n",
      "(1536,)\n",
      "torch.Size([1536])\n",
      "Parameter containing:\n",
      "tensor([-0.1518, -0.1683,  0.8580,  ..., -0.2099,  0.6263, -0.1105],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "[-0.15184316 -0.16827685  0.857969   ... -0.20985608  0.62634546\n",
      " -0.11053453]\n",
      "DenseRes1.FC1.weight DenseRes3_w0\n",
      "(2359296,)\n",
      "torch.Size([1536, 1536])\n",
      "Parameter containing:\n",
      "tensor([[-0.0485, -0.0315,  0.0267,  ...,  0.0217,  0.1374, -0.0293],\n",
      "        [ 0.0238, -0.8755, -0.0174,  ...,  0.0089,  0.0256, -0.0133],\n",
      "        [ 0.0147,  0.0582, -0.3537,  ..., -0.0422,  0.0570,  0.0144],\n",
      "        ...,\n",
      "        [-0.0108, -0.1301,  0.0031,  ..., -0.1619, -0.0622, -0.0082],\n",
      "        [ 0.0408, -0.0307,  0.0034,  ..., -0.0054, -0.5176,  0.0010],\n",
      "        [-0.0202, -0.0094,  0.0010,  ...,  0.0235,  0.0296, -0.4821]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "[-0.04850122 -0.03149954  0.02674235 ...  0.0235464   0.02964539\n",
      " -0.4821056 ]\n",
      "DenseRes1.FC1.bias DenseRes3_b0\n",
      "(1536,)\n",
      "torch.Size([1536])\n",
      "Parameter containing:\n",
      "tensor([-0.0249, -0.4983,  0.0186,  ..., -0.0382,  0.1041, -0.0624],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "[-0.02486976 -0.49826843  0.01864941 ... -0.0382012   0.10410821\n",
      " -0.0623538 ]\n",
      "Decoder.weight Decoder_w0\n",
      "(328704,)\n",
      "torch.Size([214, 1536])\n",
      "Parameter containing:\n",
      "tensor([[-8.2554e-04,  1.0519e-04, -6.0643e-04,  ...,  8.1765e-04,\n",
      "         -4.9724e-04,  1.5483e-03],\n",
      "        [ 7.6074e-04, -4.2053e-04, -8.3331e-04,  ..., -2.7852e-04,\n",
      "         -3.4136e-05, -1.8028e-03],\n",
      "        [-2.3530e-04,  8.6251e-04,  4.3416e-04,  ..., -2.3380e-04,\n",
      "         -6.2064e-04, -1.9648e-03],\n",
      "        ...,\n",
      "        [ 9.9270e-03,  1.9753e-03,  3.3445e-03,  ...,  5.2280e-03,\n",
      "          2.3635e-04, -3.6490e-03],\n",
      "        [-2.1446e-02,  8.3980e-03, -9.8637e-03,  ...,  6.7358e-04,\n",
      "          4.3792e-03,  7.0542e-03],\n",
      "        [-9.3459e-03,  5.7690e-03, -6.8732e-03,  ...,  4.8244e-03,\n",
      "          5.9706e-04,  1.7882e-03]], device='cuda:0', requires_grad=True)\n",
      "[-0.00082554  0.00010519 -0.00060643 ...  0.00482443  0.00059706\n",
      "  0.00178815]\n",
      "Decoder.bias Decoder_b0\n",
      "(214,)\n",
      "torch.Size([214])\n",
      "Parameter containing:\n",
      "tensor([ 7.9911e-04,  7.2869e-04,  5.7620e-04, -6.5038e-03, -8.0592e-03,\n",
      "         8.0241e-03, -6.1723e-03, -4.8412e-03, -5.5120e-03,  6.2513e-03,\n",
      "        -4.7115e-03, -1.1371e-02,  9.8252e-03,  3.7173e-03, -9.2683e-03,\n",
      "        -1.9624e-03, -6.4339e-03,  1.6835e-02, -7.1876e-03, -1.3464e-03,\n",
      "         1.6334e-02, -1.4762e-03,  3.0270e-04,  7.9700e-03,  4.6964e-04,\n",
      "        -5.3567e-03,  1.8576e-02,  5.3541e-04, -7.3743e-03,  6.8717e-03,\n",
      "         7.8960e-03, -2.4474e-03,  4.3727e-04, -2.0207e-03, -5.5450e-03,\n",
      "         1.7107e-02,  8.8464e-03, -3.6852e-03, -9.1405e-03,  1.1099e-02,\n",
      "         8.9032e-04, -1.1215e-02, -5.3365e-03, -5.9436e-03,  1.3988e-02,\n",
      "         1.7387e-02,  7.1854e-03, -1.5551e-02,  1.5809e-02,  7.1075e-03,\n",
      "        -1.6151e-02,  7.7747e-03,  4.2490e-03, -8.0448e-03,  4.7423e-03,\n",
      "         7.4861e-03,  5.1504e-03,  1.0593e-02,  6.4310e-03, -4.6104e-03,\n",
      "         1.2909e-02,  7.1751e-03, -1.2234e-02,  1.6739e-02,  1.0109e-02,\n",
      "        -1.2392e-02,  2.7156e-04,  4.7559e-04,  3.8418e-04,  7.9517e-04,\n",
      "        -8.1991e-04, -6.6251e-04, -7.3422e-04,  5.0388e-04, -3.6921e-04,\n",
      "        -2.2628e-05, -2.1036e-04, -2.4952e-04, -7.5594e-04, -1.1273e-03,\n",
      "         7.0273e-04, -5.0140e-04,  1.3057e-03, -1.5045e-04, -6.3059e-04,\n",
      "         1.1827e-05,  6.6543e-04,  1.3787e-04,  1.5524e-03, -2.7714e-04,\n",
      "        -9.0692e-04,  4.9238e-04,  1.9506e-04,  3.6382e-05,  2.1669e-04,\n",
      "         3.7319e-04,  3.3355e-03, -1.1577e-02, -2.5483e-03, -4.0242e-03,\n",
      "         5.3999e-03, -3.0571e-03, -5.1791e-03,  6.1008e-03, -5.1265e-03,\n",
      "        -1.0007e-02,  1.0119e-02,  5.9487e-03, -1.0016e-02,  1.1876e-02,\n",
      "        -7.5232e-03,  6.7946e-03, -1.0183e-02,  5.2384e-03, -8.2479e-03,\n",
      "         1.0722e-02, -6.6783e-03,  2.0153e-03, -2.9429e-03, -5.6485e-04,\n",
      "        -1.6006e-02, -8.2303e-03, -7.1637e-03,  1.9974e-03,  3.0936e-03,\n",
      "        -1.5355e-02,  6.4596e-05,  2.6195e-03, -1.6183e-02, -6.3814e-03,\n",
      "        -9.2690e-03, -9.6575e-04,  5.8411e-04,  2.7319e-03, -1.3404e-02,\n",
      "        -4.1463e-04, -2.3749e-03, -1.0621e-02, -6.4560e-03, -6.9394e-03,\n",
      "         5.1704e-04,  6.8119e-03,  5.8992e-03, -1.4254e-03,  6.3959e-03,\n",
      "         5.7508e-03, -1.8755e-03, -1.0113e-02, -8.4858e-03, -1.0054e-02,\n",
      "         5.1305e-03,  4.2812e-03,  5.3411e-03, -1.0337e-02, -8.6028e-03,\n",
      "        -1.3416e-02,  9.2782e-03,  9.0595e-03,  7.5199e-03,  7.7729e-03,\n",
      "         7.6879e-03,  5.8061e-03,  9.1578e-03,  8.1105e-03,  8.4774e-03,\n",
      "        -1.1205e-02, -7.1808e-03, -1.0178e-02,  9.4366e-03,  8.5045e-03,\n",
      "         8.5820e-03, -9.6454e-03, -1.6037e-03, -1.4396e-02,  1.5288e-02,\n",
      "         1.3013e-02,  1.6456e-02,  6.7736e-03,  7.3183e-03,  5.5323e-03,\n",
      "         8.6094e-03,  5.7812e-03,  1.2737e-02, -1.3246e-02, -1.9539e-03,\n",
      "        -9.8351e-03,  1.0616e-02,  6.8224e-03,  8.8441e-03, -7.3925e-04,\n",
      "         1.1526e-02, -1.6012e-02, -1.4568e-04,  1.3851e-02, -1.4648e-02,\n",
      "        -1.9798e-02, -2.1262e-02, -1.5432e-02, -1.9880e-02, -2.1041e-02,\n",
      "        -1.9452e-02, -1.9303e-02, -2.0184e-02, -2.0294e-02, -2.0654e-02,\n",
      "        -2.1018e-02, -1.5790e-02, -1.8899e-02, -2.0817e-02, -2.4259e-02,\n",
      "        -1.9407e-02, -2.0501e-02, -1.9444e-02, -1.6278e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "[ 7.99109577e-04  7.28689600e-04  5.76197228e-04 -6.50379062e-03\n",
      " -8.05923529e-03  8.02410766e-03 -6.17233524e-03 -4.84124618e-03\n",
      " -5.51197957e-03  6.25131652e-03 -4.71153203e-03 -1.13714607e-02\n",
      "  9.82520171e-03  3.71725205e-03 -9.26828664e-03 -1.96235161e-03\n",
      " -6.43390557e-03  1.68351401e-02 -7.18756346e-03 -1.34643435e-03\n",
      "  1.63342245e-02 -1.47620600e-03  3.02704051e-04  7.96996988e-03\n",
      "  4.69642138e-04 -5.35671832e-03  1.85763985e-02  5.35408850e-04\n",
      " -7.37431506e-03  6.87171333e-03  7.89595116e-03 -2.44740536e-03\n",
      "  4.37269511e-04 -2.02067662e-03 -5.54495212e-03  1.71065684e-02\n",
      "  8.84643197e-03 -3.68519546e-03 -9.14046075e-03  1.10990126e-02\n",
      "  8.90318421e-04 -1.12150041e-02 -5.33651607e-03 -5.94360614e-03\n",
      "  1.39884669e-02  1.73873622e-02  7.18540186e-03 -1.55512691e-02\n",
      "  1.58089362e-02  7.10748881e-03 -1.61513798e-02  7.77469249e-03\n",
      "  4.24897671e-03 -8.04482494e-03  4.74226661e-03  7.48611847e-03\n",
      "  5.15040895e-03  1.05928387e-02  6.43101940e-03 -4.61044442e-03\n",
      "  1.29094189e-02  7.17508420e-03 -1.22335022e-02  1.67393908e-02\n",
      "  1.01088881e-02 -1.23924306e-02  2.71564728e-04  4.75586159e-04\n",
      "  3.84177867e-04  7.95168977e-04 -8.19905486e-04 -6.62507489e-04\n",
      " -7.34221656e-04  5.03879914e-04 -3.69209214e-04 -2.26276334e-05\n",
      " -2.10362850e-04 -2.49520090e-04 -7.55943067e-04 -1.12733035e-03\n",
      "  7.02733523e-04 -5.01399336e-04  1.30565430e-03 -1.50448759e-04\n",
      " -6.30586757e-04  1.18265052e-05  6.65429281e-04  1.37874056e-04\n",
      "  1.55244116e-03 -2.77141953e-04 -9.06920002e-04  4.92382678e-04\n",
      "  1.95055487e-04  3.63815052e-05  2.16692832e-04  3.73185962e-04\n",
      "  3.33549222e-03 -1.15766879e-02 -2.54832744e-03 -4.02423134e-03\n",
      "  5.39987721e-03 -3.05712782e-03 -5.17912954e-03  6.10084552e-03\n",
      " -5.12648281e-03 -1.00072129e-02  1.01191811e-02  5.94867812e-03\n",
      " -1.00160120e-02  1.18762478e-02 -7.52324192e-03  6.79455418e-03\n",
      " -1.01832217e-02  5.23838867e-03 -8.24789423e-03  1.07215969e-02\n",
      " -6.67825108e-03  2.01528985e-03 -2.94287945e-03 -5.64848247e-04\n",
      " -1.60061792e-02 -8.23032204e-03 -7.16368295e-03  1.99737330e-03\n",
      "  3.09364102e-03 -1.53548634e-02  6.45963228e-05  2.61953427e-03\n",
      " -1.61825307e-02 -6.38138875e-03 -9.26901866e-03 -9.65753687e-04\n",
      "  5.84105379e-04  2.73193745e-03 -1.34044662e-02 -4.14627662e-04\n",
      " -2.37491704e-03 -1.06205661e-02 -6.45604683e-03 -6.93935575e-03\n",
      "  5.17035369e-04  6.81192707e-03  5.89915738e-03 -1.42537814e-03\n",
      "  6.39586709e-03  5.75078605e-03 -1.87549822e-03 -1.01133306e-02\n",
      " -8.48581269e-03 -1.00537250e-02  5.13049588e-03  4.28123446e-03\n",
      "  5.34111494e-03 -1.03371954e-02 -8.60278029e-03 -1.34160779e-02\n",
      "  9.27815679e-03  9.05954372e-03  7.51992827e-03  7.77294859e-03\n",
      "  7.68788764e-03  5.80608333e-03  9.15781315e-03  8.11049249e-03\n",
      "  8.47738609e-03 -1.12052271e-02 -7.18084583e-03 -1.01776309e-02\n",
      "  9.43663064e-03  8.50445591e-03  8.58199317e-03 -9.64537263e-03\n",
      " -1.60366111e-03 -1.43964430e-02  1.52882887e-02  1.30128413e-02\n",
      "  1.64560527e-02  6.77364785e-03  7.31834024e-03  5.53226983e-03\n",
      "  8.60936940e-03  5.78122400e-03  1.27368355e-02 -1.32459719e-02\n",
      " -1.95391639e-03 -9.83511563e-03  1.06159868e-02  6.82241982e-03\n",
      "  8.84412136e-03 -7.39254116e-04  1.15257222e-02 -1.60117038e-02\n",
      " -1.45681057e-04  1.38506293e-02 -1.46476375e-02 -1.97982863e-02\n",
      " -2.12621465e-02 -1.54324425e-02 -1.98804233e-02 -2.10414175e-02\n",
      " -1.94523912e-02 -1.93031877e-02 -2.01835483e-02 -2.02936269e-02\n",
      " -2.06544288e-02 -2.10183598e-02 -1.57898460e-02 -1.88992266e-02\n",
      " -2.08174251e-02 -2.42588427e-02 -1.94074307e-02 -2.05012411e-02\n",
      " -1.94442533e-02 -1.62778515e-02]\n"
     ]
    }
   ],
   "source": [
    "getbinname = {\n",
    "    \"Decoder.weight\": \"Decoder_w0\",\n",
    "    \"Decoder.bias\": \"Decoder_b0\",\n",
    "    \"Encoder0.weight\": \"Encoder0_w0\",\n",
    "    \"Encoder0.bias\": \"Encoder0_b0\",\n",
    "    \"Encoder1.weight\": \"Encoder1_w0\",\n",
    "    \"Encoder1.bias\": \"Encoder1_b0\",\n",
    "    \"Encoder2.weight\": \"Encoder2_w0\",\n",
    "    \"Encoder2.bias\": \"Encoder2_b0\",\n",
    "    \"DenseRes0.FC0.weight\": \"DenseRes0_w0\",\n",
    "    \"DenseRes0.FC0.bias\": \"DenseRes0_b0\",\n",
    "    \"DenseRes0.FC1.weight\": \"DenseRes1_w0\",\n",
    "    \"DenseRes0.FC1.bias\": \"DenseRes1_b0\",\n",
    "    \"DenseRes1.FC0.weight\": \"DenseRes2_w0\",\n",
    "    \"DenseRes1.FC0.bias\": \"DenseRes2_b0\",\n",
    "    \"DenseRes1.FC1.weight\": \"DenseRes3_w0\",\n",
    "    \"DenseRes1.FC1.bias\": \"DenseRes3_b0\",\n",
    "\n",
    "}\n",
    "# print(os.getcwd())\n",
    "#\n",
    "with torch.no_grad():\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, getbinname[name])\n",
    "        # fp = f\"data/ManipNetBIN/{getbinname[name]}.bin\"\n",
    "        fp = f\"{getbinname[name]}.bin\"\n",
    "        savednp = np.fromfile(fp, dtype=np.float32)\n",
    "        print(savednp.shape)\n",
    "        # savedweight = torch.from_numpy(savednp)\n",
    "        shape_ = param.shape\n",
    "        print(shape_)\n",
    "\n",
    "        # print(shape_, shape_[0], shape_[1])\n",
    "        param.copy_(torch.from_numpy(savednp.reshape(shape_, order=\"C\"))) \n",
    "        # param.copy_(torch.from_numpy(savednp.reshape(shape_, order=\"F\"))) \n",
    "        print(param)\n",
    "        print(savednp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder0.weight\n",
      "torch.Size([512, 192]) Encoder0.weight Encoder0_w0\n",
      "Encoder0.bias\n",
      "torch.Size([512]) Encoder0.bias Encoder0_b0\n",
      "Encoder1.weight\n",
      "torch.Size([512, 336]) Encoder1.weight Encoder1_w0\n",
      "Encoder1.bias\n",
      "torch.Size([512]) Encoder1.bias Encoder1_b0\n",
      "Encoder2.weight\n",
      "torch.Size([512, 1822]) Encoder2.weight Encoder2_w0\n",
      "Encoder2.bias\n",
      "torch.Size([512]) Encoder2.bias Encoder2_b0\n",
      "DenseRes0.FC0.weight\n",
      "DenseRes0.FC0.bias\n",
      "DenseRes0.FC1.weight\n",
      "DenseRes0.FC1.bias\n",
      "DenseRes1.FC0.weight\n",
      "DenseRes1.FC0.bias\n",
      "DenseRes1.FC1.weight\n",
      "DenseRes1.FC1.bias\n",
      "Decoder.weight\n",
      "torch.Size([214, 1536]) Decoder.weight Decoder_w0\n",
      "Decoder.bias\n",
      "torch.Size([214]) Decoder.bias Decoder_b0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name)\n",
    "        for k, v in bindata.items():\n",
    "            for i in range(len(net_name_list)):\n",
    "                # print(net_name_list[i][0], name)\n",
    "                if name == net_name_list[i][0] and k == net_name_list[i][1]:\n",
    "                    print(param.shape, name, k)\n",
    "                    rephape_weight = torch.reshape(torch.from_numpy(bindata[net_name_list[i][1]]), net_name_list[i][2])\n",
    "                    param.copy_(rephape_weight)\n",
    "        for i in range(len(dense_weight_list)):\n",
    "            if name == dense_weight_list[i][0]:\n",
    "                param.copy_(torch.reshape(torch.from_numpy(bindata[dense_weight_list[i][1]]), [1536, 1536]))\n",
    "            if name == dense_bias_list[i][0]:\n",
    "                param.copy_(torch.reshape(torch.from_numpy(bindata[dense_bias_list[i][1]]), [1536]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder0.weight Parameter containing:\n",
      "tensor([[-0.0751, -0.0893,  0.0815,  ..., -0.0590, -0.0180, -0.0058],\n",
      "        [-0.0455,  0.0524, -0.0306,  ..., -0.1515,  0.0012, -0.0810],\n",
      "        [-0.0329,  0.0703, -0.0476,  ...,  0.0215,  0.0864, -0.0461],\n",
      "        ...,\n",
      "        [ 0.0060,  0.0643, -0.0282,  ...,  0.0144,  0.0069, -0.0084],\n",
      "        [-0.0182,  0.0615,  0.0271,  ...,  0.0547,  0.0410, -0.0219],\n",
      "        [-0.0358,  0.0303,  0.0649,  ..., -0.0151, -0.1224, -0.0107]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Encoder0.bias Parameter containing:\n",
      "tensor([-4.3906e-01,  4.7862e-02, -1.1680e+00, -1.3886e+00, -5.3770e-01,\n",
      "        -3.2809e-01,  1.0509e+00, -4.4401e-01, -7.2452e-01, -3.2332e-01,\n",
      "        -9.3679e-01, -7.6667e-01, -7.8083e-01, -1.1598e+00, -9.9273e-01,\n",
      "        -1.1866e+00, -4.9976e-01, -1.4072e-01, -6.7747e-01, -6.7173e-01,\n",
      "        -1.0881e+00, -8.0475e-02, -6.2963e-01, -1.3231e+00, -6.4958e-01,\n",
      "        -1.0807e+00, -1.9882e-01, -9.7029e-01, -6.6112e-01, -9.4134e-01,\n",
      "        -3.9715e-01, -1.6274e-01, -3.1258e-01,  9.7770e-01,  1.5371e-01,\n",
      "         2.8020e-01, -7.7931e-01, -5.4925e-01,  1.6257e+00, -2.7447e-01,\n",
      "        -1.8523e+00, -4.0375e-01, -6.0161e-01, -4.4085e-01, -1.1014e+00,\n",
      "        -4.3666e-01,  2.3903e-01, -8.7425e-01, -1.1901e+00, -5.1821e-01,\n",
      "        -7.7406e-01, -1.0964e+00, -7.0872e-01,  5.9568e-03, -2.6934e-01,\n",
      "         2.1699e-01, -8.3018e-01, -4.2144e-01, -5.7552e-01, -7.2930e-01,\n",
      "        -2.2320e-01, -7.6321e-01, -1.0170e+00, -8.7127e-01, -3.3961e-01,\n",
      "        -8.3208e-01, -8.1641e-01,  1.0962e+00,  1.7797e+00,  1.8376e+00,\n",
      "        -2.9112e-01,  4.3535e-01, -9.8477e-01,  7.7229e-01, -2.9684e-01,\n",
      "        -9.8708e-01, -2.4607e-01, -7.3421e-01,  1.7074e-01, -8.1644e-01,\n",
      "        -7.4658e-01, -5.3343e-01,  2.0174e+00,  5.1982e-03, -3.0636e-01,\n",
      "        -2.3099e-01,  5.0989e-01, -7.5494e-01, -6.0530e-01,  4.2969e-01,\n",
      "        -3.8006e-01,  1.0005e+00, -9.3268e-01,  8.8310e-01,  1.2754e-01,\n",
      "        -8.1616e-01,  6.0620e-01, -4.9828e-01,  1.2382e-01, -2.6718e-01,\n",
      "        -3.9277e-01, -4.0351e-01, -7.8099e-01, -1.2827e+00, -7.2650e-01,\n",
      "         5.4563e-01, -8.3307e-01, -7.7926e-01, -2.1250e-01,  6.5009e-01,\n",
      "         1.8335e+00, -7.4290e-01, -3.4202e-01, -5.1086e-01, -1.0663e+00,\n",
      "        -1.5132e+00, -3.5368e-01, -7.6293e-01, -6.2816e-01, -1.9000e-01,\n",
      "        -6.8390e-01, -3.0178e-01, -8.2513e-01, -5.6426e-01, -4.7421e-01,\n",
      "        -8.5716e-01, -1.3030e+00,  9.5865e-01,  5.5428e-01, -8.2920e-01,\n",
      "        -9.5624e-01, -1.0177e+00,  4.6339e-01, -7.5144e-01, -1.1246e+00,\n",
      "        -7.1639e-01,  1.7148e-02, -9.8364e-01, -1.8453e-01,  6.0390e-02,\n",
      "         2.0198e-01, -4.4712e-02,  2.5073e-01, -7.4218e-02, -6.6577e-01,\n",
      "         8.5910e-01, -2.1423e-01,  6.8852e-01, -5.0640e-01, -6.3089e-01,\n",
      "        -1.9629e-01,  4.3821e-01,  8.5665e-01,  5.9313e-01,  1.1447e+00,\n",
      "        -9.6194e-01,  8.5572e-01, -6.6428e-01, -3.5137e-01, -3.6053e-01,\n",
      "        -8.4458e-01, -9.3414e-01,  9.5905e-01,  1.8786e+00,  8.3379e-01,\n",
      "        -7.6697e-01, -1.1236e+00, -4.8948e-01, -4.2710e-01, -8.3379e-01,\n",
      "        -1.1784e+00, -7.0696e-01,  9.6434e-01, -1.0633e+00, -1.0658e+00,\n",
      "        -7.8421e-01,  3.0586e-01, -6.2769e-01, -7.6692e-01, -3.0207e-01,\n",
      "         5.9897e-02, -4.5004e-01,  5.8605e-01, -1.3992e+00,  1.6111e+00,\n",
      "        -1.1569e+00, -8.5366e-01, -1.3812e+00, -1.1454e+00, -4.7291e-01,\n",
      "        -8.4193e-01, -1.1232e+00, -1.1582e+00, -9.4163e-01, -1.4452e+00,\n",
      "        -1.4311e-02, -1.3391e-01, -8.5392e-01, -3.2729e-01, -1.9344e-01,\n",
      "        -7.8315e-02, -7.7213e-02, -1.0502e+00, -6.3931e-03,  5.0279e-01,\n",
      "        -7.9887e-01, -4.5790e-01, -7.9856e-01, -1.2413e+00, -7.7535e-01,\n",
      "        -8.1358e-01, -6.4471e-02,  7.7888e-01, -5.7556e-01, -3.8360e-01,\n",
      "         4.3966e-02, -3.3451e-01, -6.8106e-01, -9.7699e-01,  4.8581e-01,\n",
      "        -4.7522e-01, -6.2595e-01, -8.0131e-01, -9.3152e-01, -8.2370e-01,\n",
      "        -8.4971e-01,  2.5732e-02, -5.0579e-01, -1.2371e+00,  9.1078e-02,\n",
      "        -6.4143e-01,  1.4353e+00, -1.2896e-01, -4.5717e-01, -5.3357e-01,\n",
      "         1.6357e+00,  4.9011e-01, -1.1034e+00, -5.4421e-01,  1.6217e+00,\n",
      "        -3.3295e-01,  1.4743e+00, -1.2668e+00, -1.5143e+00, -6.9948e-01,\n",
      "        -9.3250e-01, -9.2580e-01,  8.2835e-01, -8.6974e-01, -6.6888e-01,\n",
      "        -1.0857e+00, -6.4139e-01, -8.7056e-01, -9.3600e-01,  1.2207e+00,\n",
      "         1.6625e-01, -3.0974e-01, -9.0889e-01, -1.4639e+00, -8.6248e-01,\n",
      "        -7.4395e-02,  1.2609e+00, -5.8373e-01, -3.3057e-02,  9.6363e-02,\n",
      "        -6.5085e-01, -1.0799e+00, -5.1537e-01, -6.7712e-01, -4.2395e-01,\n",
      "        -1.0789e+00,  1.1202e+00, -8.5289e-01, -9.9582e-01, -7.2808e-01,\n",
      "         7.7262e-01, -7.6762e-01, -1.4577e+00, -6.1644e-01, -5.9999e-01,\n",
      "        -1.0225e+00, -1.1600e+00, -6.8821e-01,  6.0551e-02, -9.3566e-01,\n",
      "        -6.9541e-01, -2.3897e-01, -6.5867e-01,  1.2061e+00,  7.8379e-01,\n",
      "        -7.3333e-01, -8.1682e-01, -1.2977e+00,  1.2979e+00, -6.4435e-01,\n",
      "        -1.1958e-01,  1.2668e+00, -8.6745e-01, -6.2423e-01, -5.5419e-01,\n",
      "         5.9595e-01, -5.2042e-02,  9.8364e-01, -9.8834e-01, -9.3627e-01,\n",
      "        -1.2083e+00, -8.7637e-01,  7.8258e-01,  1.4542e-02,  8.7818e-01,\n",
      "        -4.4684e-01,  3.5432e-02, -3.7621e-01, -6.5344e-01, -1.0211e+00,\n",
      "         2.4372e-01, -1.0660e+00, -3.7948e-01, -1.9310e-01, -9.1725e-01,\n",
      "        -5.6280e-01,  8.9085e-01, -6.2629e-01, -6.7245e-01, -7.7291e-01,\n",
      "        -2.2979e-01,  8.0685e-01, -4.9420e-01, -7.5227e-01, -6.1668e-01,\n",
      "        -1.5337e-01, -3.7693e-01, -1.2383e+00, -3.1109e-01, -1.1811e+00,\n",
      "        -7.6794e-01, -8.8006e-01, -1.3393e-01,  1.0998e+00, -7.0404e-01,\n",
      "         4.9956e-01, -1.1982e+00, -5.2051e-01, -9.2728e-01, -1.1901e+00,\n",
      "        -5.8223e-01,  1.0728e+00,  3.5865e-01,  4.2351e-01, -5.6954e-01,\n",
      "        -8.5222e-01, -9.3196e-01, -6.9479e-01, -1.0820e+00, -5.2760e-01,\n",
      "        -8.6313e-01, -8.6442e-01,  1.6214e-01, -7.6223e-01, -3.0522e-01,\n",
      "         2.0889e-01,  1.7105e-01, -5.8668e-01, -7.8614e-01, -1.6590e-01,\n",
      "        -2.2922e-01,  7.6972e-01, -2.9553e-01,  1.0000e+00,  1.0192e-01,\n",
      "        -1.0229e-01, -2.7340e-01, -4.6597e-01,  7.0842e-01, -6.6384e-01,\n",
      "        -5.1198e-01, -6.9132e-01, -9.2252e-01,  5.6327e-01, -8.0773e-01,\n",
      "        -7.3454e-01, -4.6876e-01,  4.7758e-01, -5.2074e-02,  6.4325e-01,\n",
      "        -1.0025e+00,  7.4789e-01, -9.8580e-01, -6.1363e-01,  6.6589e-01,\n",
      "        -1.1749e+00, -6.9884e-01,  1.0465e+00, -1.9920e-01, -3.8599e-01,\n",
      "        -6.2273e-01, -8.2935e-01, -7.9309e-01, -1.2689e+00, -3.2974e-01,\n",
      "        -5.0878e-01, -8.6923e-01, -9.4125e-01, -6.3415e-01, -1.2358e+00,\n",
      "        -7.0380e-01,  2.7919e-01, -1.0160e+00,  2.9928e-01, -8.4400e-01,\n",
      "        -8.3064e-01, -9.0498e-01, -2.2070e-01, -1.1601e+00,  3.1661e-01,\n",
      "        -1.3671e+00,  5.0174e-01, -4.1611e-01, -1.9844e-01, -7.1928e-01,\n",
      "        -3.6111e-01, -8.7884e-01, -5.7047e-01, -4.9899e-01, -1.0670e+00,\n",
      "        -6.5430e-01, -6.8204e-01, -1.1673e+00,  8.0272e-01,  9.0036e-02,\n",
      "        -1.4400e+00,  2.9176e-01, -8.9749e-01, -6.7548e-01, -9.3913e-01,\n",
      "        -6.4014e-01,  8.7563e-01, -9.0269e-02, -1.8495e-01,  6.8408e-01,\n",
      "        -9.9054e-01, -4.7816e-01, -7.0488e-01, -4.5079e-01, -1.4490e-01,\n",
      "         5.8515e-01, -8.6970e-02, -6.2257e-01, -4.5183e-01,  1.0062e+00,\n",
      "        -8.6692e-01, -5.6137e-01,  1.6995e+00, -2.5570e-01,  1.0390e+00,\n",
      "        -1.0809e+00, -1.3396e+00, -8.2565e-01, -3.9317e-01, -4.0768e-01,\n",
      "        -7.7541e-01, -4.3306e-01,  7.1105e-01, -1.1624e+00,  1.0518e+00,\n",
      "        -8.0386e-01, -1.5669e-01, -6.2096e-01, -6.3850e-01, -2.7510e-01,\n",
      "         9.1868e-01, -5.6608e-01, -7.4105e-01, -6.6120e-01, -5.0306e-01,\n",
      "        -1.9951e-01, -9.9964e-01, -4.9497e-01,  3.6573e-01, -5.3219e-01,\n",
      "        -1.2454e-01,  6.0667e-01,  1.1040e+00, -4.9112e-01, -6.8293e-01,\n",
      "        -7.3088e-01,  9.2730e-01, -9.3933e-01, -1.0117e+00, -4.6640e-01,\n",
      "        -8.6700e-01, -1.3305e+00, -5.6797e-01, -1.5559e-04, -7.6136e-01,\n",
      "        -5.3700e-01, -8.6403e-01, -5.6233e-01, -7.6115e-01, -1.0163e-01,\n",
      "        -7.9931e-01, -8.7818e-02, -6.4648e-01,  1.3215e+00, -1.0346e+00,\n",
      "         9.9492e-01, -7.8282e-01, -1.0069e+00, -8.3604e-01, -4.4964e-01,\n",
      "        -3.8046e-01, -7.2048e-01], device='cuda:0', requires_grad=True)\n",
      "Encoder1.weight Parameter containing:\n",
      "tensor([[ 0.0749, -0.0369, -0.0309,  ..., -0.0184,  0.0093,  0.0648],\n",
      "        [ 0.0566, -0.0327, -0.0441,  ..., -0.0904, -0.0137, -0.0701],\n",
      "        [-0.0557, -0.0615,  0.0332,  ..., -0.0514, -0.0148, -0.0015],\n",
      "        ...,\n",
      "        [ 0.0429, -0.0666, -0.0625,  ..., -0.1661,  0.2204, -0.0098],\n",
      "        [-0.0430,  0.0243,  0.0069,  ..., -0.0329,  0.0024,  0.0509],\n",
      "        [-0.0559, -0.0146,  0.0019,  ..., -0.0258,  0.0226, -0.0403]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Encoder1.bias Parameter containing:\n",
      "tensor([-0.8888, -1.0076, -0.9453, -1.1037, -0.9275, -0.8630, -0.8056, -0.8400,\n",
      "        -1.0474, -0.9582, -1.1243, -0.7306, -1.0330, -1.0848, -0.9526, -1.0446,\n",
      "        -0.8230, -1.0557, -0.7865, -0.7681, -1.0364, -0.7908, -1.0357, -0.8983,\n",
      "        -0.8502, -0.7437, -0.8666, -0.8393, -1.1218, -1.0878, -0.9887, -0.7803,\n",
      "        -1.4398, -0.9827, -0.8727, -1.0343, -0.9160, -0.9059, -1.0915, -1.2934,\n",
      "        -0.9181, -0.8255, -1.0449, -0.9881, -0.7136, -0.7349, -0.8952, -1.0563,\n",
      "        -0.8364, -1.0057, -0.8321, -0.8928, -0.8484, -1.0322, -1.2118, -1.1346,\n",
      "        -0.9346, -0.9379, -1.0691, -0.9966, -1.0253, -0.9700, -0.8659, -0.8239,\n",
      "        -0.7564, -1.1317, -0.6116, -1.0400, -0.9048, -0.9694, -0.7313, -0.7587,\n",
      "        -1.0928, -0.9292, -0.8972, -1.0330, -0.9855, -0.9848, -1.0315, -0.9555,\n",
      "        -1.0273, -1.1015, -0.9820, -0.9014, -0.7002, -1.0407, -1.0059, -0.7879,\n",
      "        -1.0773, -0.4498, -0.6656, -0.9709, -0.8627, -0.8778, -1.0444, -0.7572,\n",
      "        -0.8143, -1.2128, -0.9560, -1.0396, -1.1574, -0.8249, -0.9399, -1.0542,\n",
      "        -1.0823, -0.9553, -1.0058, -0.8866, -0.9373, -0.6494, -0.9181, -0.9803,\n",
      "        -0.7310, -0.8678, -1.0007, -0.9009, -1.1021, -0.1258, -0.8575, -0.8617,\n",
      "        -0.8220, -0.9378, -1.0890, -0.8330, -0.9790, -0.7850, -0.3375, -0.9433,\n",
      "        -0.6696, -0.7704, -0.8227, -0.8900, -0.7431, -1.2360, -0.8915, -0.9224,\n",
      "        -1.0594, -0.7549, -0.7711, -1.0445, -0.6866, -1.0305, -0.7601, -0.8989,\n",
      "        -0.6484, -1.0058, -1.0404, -1.0204, -1.0670, -1.0908, -1.0506, -0.6865,\n",
      "        -0.9991, -1.0376, -0.8119, -0.9682, -0.7175, -0.9248, -0.8482, -1.0869,\n",
      "        -1.0335, -0.9436, -0.9217, -1.0773, -0.6050, -1.1362, -0.7659, -0.9179,\n",
      "        -0.9544, -0.6986, -0.7307, -0.7837, -1.0532, -1.0450, -1.2055, -1.2261,\n",
      "        -0.8374, -1.1098, -0.8356, -0.8852, -0.8766, -1.0188, -1.1296, -1.0711,\n",
      "        -1.1192, -0.9496, -1.1673, -0.9768, -0.9827, -0.8963, -0.8340, -0.8625,\n",
      "        -0.7848, -0.8586, -0.7954, -1.0133, -0.8634, -0.9060, -1.1970, -0.8967,\n",
      "        -0.9998, -1.1654, -0.7689, -0.7758, -1.0857, -0.9619, -1.0237, -0.9397,\n",
      "        -0.7436, -0.6887, -0.9336, -0.9066, -0.7518, -0.9698, -0.8845, -0.7623,\n",
      "        -1.4690, -1.1430, -1.1195, -1.0151, -0.8141, -0.8812, -0.6365, -0.7073,\n",
      "        -0.7594, -0.9350, -0.9947, -0.8825, -0.8539, -0.9112, -1.0258, -1.1078,\n",
      "        -0.8958, -0.8308, -0.9671, -0.8310, -1.1104, -0.8286, -1.0262, -0.7728,\n",
      "        -0.8146, -0.7374, -1.1970, -1.0823, -1.1032, -0.8836, -0.7582, -0.9844,\n",
      "        -1.1346, -0.9427, -0.9012, -0.8724, -0.6528, -0.7799, -1.0050, -1.0491,\n",
      "        -0.9489, -1.1249, -0.5613, -1.0079, -0.8735, -1.1313, -1.0967, -1.0333,\n",
      "        -0.8021, -1.0462, -1.1164, -0.9150, -0.9814, -1.0445, -1.0262, -0.8249,\n",
      "        -1.1222, -1.1237, -1.2142, -0.8908, -1.0601, -0.8540, -0.9588, -0.9731,\n",
      "        -0.9826, -1.2438, -1.0067, -0.9847, -0.9780, -1.7346, -0.9803, -1.0015,\n",
      "        -0.8705, -1.2836, -1.0138, -0.8688, -1.1646, -1.0499, -0.4535, -0.9389,\n",
      "        -0.8371, -0.8127, -1.0697, -0.9084, -1.0771, -1.0756, -0.8713, -0.8277,\n",
      "        -1.0469, -0.9485, -1.0311, -0.8313, -0.9378, -0.9846, -0.8931, -0.9728,\n",
      "        -0.9004, -1.0419, -0.8654, -1.0742, -0.8859, -0.9309, -1.1415, -0.9094,\n",
      "        -1.5257, -0.8559, -0.7822, -1.0267, -0.7765, -0.8622, -0.9703, -0.7295,\n",
      "        -1.0836, -0.7406, -0.8620, -0.7737, -1.0271, -0.5674, -0.7836, -0.8377,\n",
      "        -0.7316, -0.5626, -0.7518, -0.9961, -0.9958, -0.9959, -0.7538, -1.0824,\n",
      "        -0.9866, -0.8271, -0.9531, -0.9728, -0.8510, -0.8145, -0.7969, -0.8666,\n",
      "        -0.8561, -0.8437, -0.9830, -1.1277, -0.6824, -0.9183, -0.7992, -0.4922,\n",
      "        -0.7682, -0.5790, -0.8403, -0.9242, -0.9469, -1.1167, -0.6529, -0.8533,\n",
      "        -1.0876, -0.8777, -0.9963, -0.7336, -1.0545, -1.1081, -0.8628, -0.6950,\n",
      "        -1.1514, -0.6708, -0.9038, -0.8336, -1.0233, -0.8313, -1.0695, -0.8986,\n",
      "        -0.7910, -0.8355, -1.0823, -1.0193, -0.7091, -0.9027, -0.6446, -0.6524,\n",
      "        -0.7964, -1.0699, -0.9329, -0.6908, -1.0075, -0.7816, -1.3074, -0.8876,\n",
      "        -0.6870, -1.0474, -0.5319, -1.1477, -0.9085, -1.0794, -1.0510, -0.8662,\n",
      "        -0.8437, -0.9579, -0.9231, -0.7004, -0.8112, -0.8163, -0.8340, -0.9590,\n",
      "        -0.5366, -0.8549, -0.8262, -0.8646, -1.1485, -0.9203, -0.7185, -0.9567,\n",
      "        -1.1508, -1.2308, -0.8046, -1.1062, -0.9151, -0.9427, -1.0795, -0.9024,\n",
      "        -0.6809, -0.6924, -0.8688, -0.8941, -1.0438, -1.3090, -1.0683, -0.8500,\n",
      "        -0.8167, -0.7334, -0.7048, -1.0177, -0.8901, -0.9481, -0.8522, -1.0359,\n",
      "        -0.9960, -1.1091, -0.8363, -0.9793, -1.0408, -1.0166, -0.9180, -0.9616,\n",
      "        -0.9228, -0.9110, -1.0107, -0.7788, -1.0881, -0.8158, -0.9736, -1.0743,\n",
      "        -0.9659, -0.7809, -0.8382, -0.5700, -1.0982, -0.6111, -0.8258, -0.7070,\n",
      "        -0.9963, -1.0094, -0.6633, -0.9072, -1.0403, -0.8184, -0.5978, -0.9522,\n",
      "        -0.7683, -0.8101, -1.0779, -0.7848, -1.1047, -1.0643, -1.0619, -0.9517,\n",
      "        -1.0518, -1.0823, -0.8650, -0.8105, -0.7492, -0.8736, -0.5541, -0.9405,\n",
      "        -0.7980, -0.7885, -0.9775, -0.7233, -1.1002, -0.8389, -0.8596, -0.9720,\n",
      "        -0.9944, -0.9795, -1.0157, -0.9656, -1.0747, -0.9373, -0.9533, -1.3089],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Encoder2.weight Parameter containing:\n",
      "tensor([[-1.3361e-02, -1.7455e-02, -4.7904e-03,  ..., -9.7306e-02,\n",
      "         -4.4195e-02, -5.6793e-02],\n",
      "        [ 6.8297e-02, -4.4632e-02, -1.0952e-02,  ..., -8.5492e-02,\n",
      "          5.6882e-02, -5.4690e-03],\n",
      "        [ 1.0006e-01,  1.0777e-02, -2.3435e-02,  ...,  1.1194e-01,\n",
      "         -3.5329e-02, -8.3537e-02],\n",
      "        ...,\n",
      "        [ 6.4019e-02,  7.8077e-02,  6.8351e-02,  ...,  3.5796e-01,\n",
      "          5.5197e-02, -5.3764e-02],\n",
      "        [ 8.4693e-02,  1.2061e-01,  6.3433e-02,  ...,  1.4407e-01,\n",
      "         -1.2749e-02, -2.6650e-02],\n",
      "        [ 1.1588e-01,  1.0543e-01,  5.2695e-03,  ..., -4.5953e-02,\n",
      "         -8.6002e-05,  1.0513e-01]], device='cuda:0', requires_grad=True)\n",
      "Encoder2.bias Parameter containing:\n",
      "tensor([-1.5927, -1.4015, -1.1201, -1.8844, -1.9497, -1.3667, -1.4710, -1.4563,\n",
      "        -1.1907, -0.9385, -1.4060, -1.5737, -1.4315, -1.0672, -1.7021, -0.9704,\n",
      "        -1.6149, -1.5217, -1.2934, -1.7769, -1.3949, -1.5239, -1.6150, -1.4001,\n",
      "        -1.4085, -1.3620, -1.9522, -1.9692, -1.5474, -1.4026, -1.1931, -0.5997,\n",
      "        -1.0898, -1.5129, -1.2172, -1.3592, -1.2393, -1.3468, -1.2688, -1.1243,\n",
      "        -1.3202, -1.4144, -1.5063, -1.3166, -1.2533, -1.4259,  0.3237, -1.1241,\n",
      "        -1.1292, -1.6249, -1.5221, -1.5608, -1.2509, -1.3242, -1.4866, -1.7007,\n",
      "        -1.0774, -1.3766, -1.6013, -1.0920, -1.0012, -1.3568, -1.6823, -1.4959,\n",
      "        -1.5220, -1.7318, -1.1582, -1.2673, -1.3256, -1.1628, -1.3145, -1.4582,\n",
      "        -1.5587, -1.4703, -1.1190, -1.5670, -1.6148, -1.4526, -1.2984, -1.4331,\n",
      "        -1.7149, -1.0494, -1.4660, -1.3035, -1.4282, -1.2627, -1.4415, -1.4562,\n",
      "        -1.0282, -1.7169, -1.6399, -0.7384, -1.2733, -1.6672, -1.6260, -1.2213,\n",
      "        -1.5575, -1.5151, -1.5493, -1.5480, -1.2572, -1.0622, -1.5120, -1.3660,\n",
      "        -0.9192, -1.6521, -1.2626, -1.5872, -1.0379, -1.2053, -1.6189, -1.6781,\n",
      "        -1.8070, -1.6824, -1.3032, -1.6219, -1.3047, -1.7215, -0.9563, -1.2035,\n",
      "        -1.5118, -1.5348, -1.6799, -1.4289, -1.8798, -0.7590, -1.3109, -1.1192,\n",
      "        -1.2521, -1.4328, -1.5419, -1.3113, -1.2943, -1.3574, -1.3348, -0.8675,\n",
      "        -1.2307, -1.4416, -1.2194, -1.4722, -1.4913, -1.3074, -1.1175, -0.9173,\n",
      "        -1.0153, -1.4328, -1.3417, -0.4013, -1.4231, -1.5359, -1.0053, -1.4289,\n",
      "        -1.5490, -1.1769, -1.6046, -1.2823, -1.8687, -1.4223, -1.3304, -1.3551,\n",
      "        -1.0711, -1.1524, -0.5180, -1.8593, -1.3777, -1.1464, -1.2811, -1.2308,\n",
      "        -1.3391, -1.5064, -1.5086, -0.3384, -1.3297, -1.7657, -1.5200, -1.4808,\n",
      "        -1.3787, -1.1307, -1.2956, -1.2300, -0.7137, -1.6403, -1.2833, -1.2609,\n",
      "        -1.2208, -1.0944, -1.4163, -1.4535, -1.7442, -1.1736, -1.4423, -0.7774,\n",
      "        -1.6892, -1.3148, -1.4443, -0.8369, -1.4366, -1.3776, -1.0446, -1.7209,\n",
      "        -1.6584, -1.4959, -1.4184, -1.2634, -1.6722, -1.2912, -1.6656, -1.6366,\n",
      "        -1.4101, -1.1486, -1.3220, -1.3758, -1.9152, -1.5024, -1.1129, -1.4169,\n",
      "        -1.2199, -1.2757, -1.4424, -1.2993, -1.3998, -1.8113, -1.8278, -1.8729,\n",
      "         0.5483, -1.0278, -1.5428, -1.3204, -0.9481, -1.7328, -1.5832, -1.5867,\n",
      "        -1.9324, -1.2838, -1.3105, -1.6723, -1.5227, -1.3714, -1.1755, -1.3142,\n",
      "        -1.5687, -1.7204, -1.5723, -1.5585, -0.9637, -1.3068, -1.3721, -1.5686,\n",
      "        -1.5802, -1.4024, -1.5671, -1.7383, -1.6320, -1.2363, -1.4999, -1.3201,\n",
      "        -1.4042, -1.3260, -0.9557, -1.7510, -1.4607, -1.3937, -0.7571, -1.4642,\n",
      "        -1.3227, -0.5073, -1.2402, -1.4242, -1.0634, -1.4925, -1.1722, -1.6921,\n",
      "        -1.8705, -1.5220, -1.4796, -1.3880, -1.4167, -1.3146, -1.3443, -1.0554,\n",
      "        -1.5916, -1.5723, -1.3658, -1.2239, -1.5555, -0.7871, -1.2475, -1.1572,\n",
      "        -1.4063, -1.4519, -0.9218, -1.5896, -1.6632, -1.9011, -1.0407, -1.4727,\n",
      "        -1.4411, -1.4091, -1.4154, -1.6117, -1.3345, -1.4853, -1.3506, -1.5172,\n",
      "        -1.5790, -1.6964, -1.0952, -1.3796, -0.9391, -1.1425, -1.2903, -1.3590,\n",
      "        -1.6289, -1.4314, -1.8317, -1.4496, -1.2959, -1.4025, -1.4165, -1.4939,\n",
      "        -0.9182, -0.4959, -0.3393, -1.3933, -0.9509, -1.3339, -0.9281, -1.0430,\n",
      "        -0.7114, -1.0609, -1.4282, -1.3717, -0.2411, -1.3362, -1.1925, -1.4284,\n",
      "        -1.7342, -1.2205, -1.4861, -1.2393, -1.3874, -0.3990, -1.2392, -1.3176,\n",
      "        -1.5699, -1.2425, -1.5035, -1.3737, -1.4493, -1.3290, -1.2039, -1.3805,\n",
      "        -1.2432, -1.0850, -1.3134, -1.4570, -1.2211, -1.5850, -1.6850, -1.5849,\n",
      "        -1.5255, -1.4872, -1.5271, -1.4773, -1.2564, -1.4447, -1.0700, -1.5707,\n",
      "        -1.3802, -1.7729, -1.7383, -1.2542, -1.3664, -1.2986, -1.5250, -1.2861,\n",
      "        -1.3444, -1.1481, -1.2283, -1.0738, -1.4314, -0.4766, -1.3161, -1.4990,\n",
      "        -1.1914, -1.4021, -1.2919, -1.2726, -0.1770, -1.3709, -1.5004, -1.6098,\n",
      "        -1.2890, -1.6665, -1.5052, -1.7415, -1.6479, -1.1088, -1.5413, -0.9684,\n",
      "        -0.2076, -1.4458, -1.6123, -1.6970, -1.4718, -1.6403, -1.5962, -1.4113,\n",
      "        -1.7102, -1.4563,  0.3793, -1.5889, -1.3262, -1.3859, -0.4609, -1.3226,\n",
      "        -1.4637, -1.3670, -1.4897, -1.3941, -1.4414, -1.6461, -1.4384, -1.3279,\n",
      "        -1.0757, -2.0033, -1.6206, -1.5272, -0.2803, -0.8975, -1.3095, -1.6226,\n",
      "        -1.2377, -1.4459, -1.6165, -1.1601, -1.1733, -1.6781, -1.6626, -1.3978,\n",
      "        -1.0958, -1.1901, -0.7517, -1.4023, -1.5251, -1.2098, -1.4678, -1.4356,\n",
      "        -1.4656, -1.1888, -1.2619, -1.7398, -1.5448, -1.5031, -1.3596, -1.0912,\n",
      "        -1.4630, -1.5091, -1.3720, -1.6804, -1.3007, -1.4108, -1.3724, -1.6002,\n",
      "        -1.4363, -1.6359, -1.5909, -1.7693, -1.5345, -1.1568, -1.4743, -1.3983,\n",
      "        -1.5622, -1.2929, -1.7790, -1.8617, -1.4979, -0.5016, -1.4051, -1.7093,\n",
      "        -1.5345, -1.2651, -1.9046, -1.6513, -1.5764, -1.8439, -1.5616, -1.3877,\n",
      "        -0.0642, -1.3873, -1.4258, -1.7834, -1.6602, -0.6489, -1.4892, -1.5114,\n",
      "        -1.4861, -1.3542, -1.2671, -1.5881, -1.5681, -0.9485, -0.7969, -1.6846,\n",
      "        -1.3999, -1.4649, -1.3012, -1.4593, -1.3316, -1.4484, -1.4714, -1.2102],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "DenseRes0.FC0.weight Parameter containing:\n",
      "tensor([[ 0.0090, -0.0363,  0.0320,  ...,  0.0125, -0.0421, -0.0202],\n",
      "        [ 0.0037,  0.0243, -0.0054,  ..., -0.0451, -0.0304, -0.0174],\n",
      "        [-0.0037, -0.0115, -0.1683,  ...,  0.0432,  0.0082, -0.0126],\n",
      "        ...,\n",
      "        [-0.0277,  0.0131, -0.0233,  ..., -0.1338,  0.0186, -0.1066],\n",
      "        [ 0.1042, -0.0179,  0.0643,  ...,  0.0136, -0.0786,  0.0380],\n",
      "        [-0.0545,  0.0669, -0.0514,  ...,  0.0671, -0.1717, -0.1112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "DenseRes0.FC0.bias Parameter containing:\n",
      "tensor([-0.0294, -0.0458,  0.0791,  ..., -0.0211, -0.1323, -0.0643],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "DenseRes0.FC1.weight Parameter containing:\n",
      "tensor([[-0.0240, -0.0419, -0.0106,  ..., -0.0550,  0.0624, -0.0773],\n",
      "        [ 0.0040, -0.0152,  0.0026,  ..., -0.1249,  0.0069, -0.0022],\n",
      "        [-0.0327,  0.0239, -0.2403,  ...,  0.0503, -0.1438, -0.0520],\n",
      "        ...,\n",
      "        [-0.0250, -0.0344, -0.1712,  ..., -0.2954, -0.0227,  0.1415],\n",
      "        [-0.0026, -0.0336,  0.0867,  ..., -0.0502, -0.4945,  0.1028],\n",
      "        [ 0.0280, -0.0271, -0.2191,  ..., -0.0514, -0.0389, -0.1367]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "DenseRes0.FC1.bias Parameter containing:\n",
      "tensor([ 0.0734, -0.3294, -0.3978,  ..., -0.5254, -0.7873, -0.2056],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "DenseRes1.FC0.weight Parameter containing:\n",
      "tensor([[-0.0762, -0.0660, -0.0273,  ...,  0.0266,  0.0362,  0.0253],\n",
      "        [-0.0124, -0.0978,  0.0200,  ...,  0.0414, -0.0138, -0.0253],\n",
      "        [-0.0267,  0.0024, -0.6002,  ...,  0.1154, -0.0468, -0.0547],\n",
      "        ...,\n",
      "        [ 0.0324, -0.0412, -0.0083,  ..., -0.1343,  0.0057, -0.0159],\n",
      "        [ 0.0303,  0.0665, -0.0051,  ...,  0.0098, -0.3463,  0.0044],\n",
      "        [-0.0065,  0.0246, -0.0161,  ..., -0.0527,  0.0030, -0.2432]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "DenseRes1.FC0.bias Parameter containing:\n",
      "tensor([-0.1518, -0.1683,  0.8580,  ..., -0.2099,  0.6263, -0.1105],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "DenseRes1.FC1.weight Parameter containing:\n",
      "tensor([[-0.0485, -0.0315,  0.0267,  ...,  0.0217,  0.1374, -0.0293],\n",
      "        [ 0.0238, -0.8755, -0.0174,  ...,  0.0089,  0.0256, -0.0133],\n",
      "        [ 0.0147,  0.0582, -0.3537,  ..., -0.0422,  0.0570,  0.0144],\n",
      "        ...,\n",
      "        [-0.0108, -0.1301,  0.0031,  ..., -0.1619, -0.0622, -0.0082],\n",
      "        [ 0.0408, -0.0307,  0.0034,  ..., -0.0054, -0.5176,  0.0010],\n",
      "        [-0.0202, -0.0094,  0.0010,  ...,  0.0235,  0.0296, -0.4821]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "DenseRes1.FC1.bias Parameter containing:\n",
      "tensor([-0.0249, -0.4983,  0.0186,  ..., -0.0382,  0.1041, -0.0624],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Decoder.weight Parameter containing:\n",
      "tensor([[-8.2554e-04,  1.0519e-04, -6.0643e-04,  ...,  8.1765e-04,\n",
      "         -4.9724e-04,  1.5483e-03],\n",
      "        [ 7.6074e-04, -4.2053e-04, -8.3331e-04,  ..., -2.7852e-04,\n",
      "         -3.4136e-05, -1.8028e-03],\n",
      "        [-2.3530e-04,  8.6251e-04,  4.3416e-04,  ..., -2.3380e-04,\n",
      "         -6.2064e-04, -1.9648e-03],\n",
      "        ...,\n",
      "        [ 9.9270e-03,  1.9753e-03,  3.3445e-03,  ...,  5.2280e-03,\n",
      "          2.3635e-04, -3.6490e-03],\n",
      "        [-2.1446e-02,  8.3980e-03, -9.8637e-03,  ...,  6.7358e-04,\n",
      "          4.3792e-03,  7.0542e-03],\n",
      "        [-9.3459e-03,  5.7690e-03, -6.8732e-03,  ...,  4.8244e-03,\n",
      "          5.9706e-04,  1.7882e-03]], device='cuda:0', requires_grad=True)\n",
      "Decoder.bias Parameter containing:\n",
      "tensor([ 7.9911e-04,  7.2869e-04,  5.7620e-04, -6.5038e-03, -8.0592e-03,\n",
      "         8.0241e-03, -6.1723e-03, -4.8412e-03, -5.5120e-03,  6.2513e-03,\n",
      "        -4.7115e-03, -1.1371e-02,  9.8252e-03,  3.7173e-03, -9.2683e-03,\n",
      "        -1.9624e-03, -6.4339e-03,  1.6835e-02, -7.1876e-03, -1.3464e-03,\n",
      "         1.6334e-02, -1.4762e-03,  3.0270e-04,  7.9700e-03,  4.6964e-04,\n",
      "        -5.3567e-03,  1.8576e-02,  5.3541e-04, -7.3743e-03,  6.8717e-03,\n",
      "         7.8960e-03, -2.4474e-03,  4.3727e-04, -2.0207e-03, -5.5450e-03,\n",
      "         1.7107e-02,  8.8464e-03, -3.6852e-03, -9.1405e-03,  1.1099e-02,\n",
      "         8.9032e-04, -1.1215e-02, -5.3365e-03, -5.9436e-03,  1.3988e-02,\n",
      "         1.7387e-02,  7.1854e-03, -1.5551e-02,  1.5809e-02,  7.1075e-03,\n",
      "        -1.6151e-02,  7.7747e-03,  4.2490e-03, -8.0448e-03,  4.7423e-03,\n",
      "         7.4861e-03,  5.1504e-03,  1.0593e-02,  6.4310e-03, -4.6104e-03,\n",
      "         1.2909e-02,  7.1751e-03, -1.2234e-02,  1.6739e-02,  1.0109e-02,\n",
      "        -1.2392e-02,  2.7156e-04,  4.7559e-04,  3.8418e-04,  7.9517e-04,\n",
      "        -8.1991e-04, -6.6251e-04, -7.3422e-04,  5.0388e-04, -3.6921e-04,\n",
      "        -2.2628e-05, -2.1036e-04, -2.4952e-04, -7.5594e-04, -1.1273e-03,\n",
      "         7.0273e-04, -5.0140e-04,  1.3057e-03, -1.5045e-04, -6.3059e-04,\n",
      "         1.1827e-05,  6.6543e-04,  1.3787e-04,  1.5524e-03, -2.7714e-04,\n",
      "        -9.0692e-04,  4.9238e-04,  1.9506e-04,  3.6382e-05,  2.1669e-04,\n",
      "         3.7319e-04,  3.3355e-03, -1.1577e-02, -2.5483e-03, -4.0242e-03,\n",
      "         5.3999e-03, -3.0571e-03, -5.1791e-03,  6.1008e-03, -5.1265e-03,\n",
      "        -1.0007e-02,  1.0119e-02,  5.9487e-03, -1.0016e-02,  1.1876e-02,\n",
      "        -7.5232e-03,  6.7946e-03, -1.0183e-02,  5.2384e-03, -8.2479e-03,\n",
      "         1.0722e-02, -6.6783e-03,  2.0153e-03, -2.9429e-03, -5.6485e-04,\n",
      "        -1.6006e-02, -8.2303e-03, -7.1637e-03,  1.9974e-03,  3.0936e-03,\n",
      "        -1.5355e-02,  6.4596e-05,  2.6195e-03, -1.6183e-02, -6.3814e-03,\n",
      "        -9.2690e-03, -9.6575e-04,  5.8411e-04,  2.7319e-03, -1.3404e-02,\n",
      "        -4.1463e-04, -2.3749e-03, -1.0621e-02, -6.4560e-03, -6.9394e-03,\n",
      "         5.1704e-04,  6.8119e-03,  5.8992e-03, -1.4254e-03,  6.3959e-03,\n",
      "         5.7508e-03, -1.8755e-03, -1.0113e-02, -8.4858e-03, -1.0054e-02,\n",
      "         5.1305e-03,  4.2812e-03,  5.3411e-03, -1.0337e-02, -8.6028e-03,\n",
      "        -1.3416e-02,  9.2782e-03,  9.0595e-03,  7.5199e-03,  7.7729e-03,\n",
      "         7.6879e-03,  5.8061e-03,  9.1578e-03,  8.1105e-03,  8.4774e-03,\n",
      "        -1.1205e-02, -7.1808e-03, -1.0178e-02,  9.4366e-03,  8.5045e-03,\n",
      "         8.5820e-03, -9.6454e-03, -1.6037e-03, -1.4396e-02,  1.5288e-02,\n",
      "         1.3013e-02,  1.6456e-02,  6.7736e-03,  7.3183e-03,  5.5323e-03,\n",
      "         8.6094e-03,  5.7812e-03,  1.2737e-02, -1.3246e-02, -1.9539e-03,\n",
      "        -9.8351e-03,  1.0616e-02,  6.8224e-03,  8.8441e-03, -7.3925e-04,\n",
      "         1.1526e-02, -1.6012e-02, -1.4568e-04,  1.3851e-02, -1.4648e-02,\n",
      "        -1.9798e-02, -2.1262e-02, -1.5432e-02, -1.9880e-02, -2.1041e-02,\n",
      "        -1.9452e-02, -1.9303e-02, -2.0184e-02, -2.0294e-02, -2.0654e-02,\n",
      "        -2.1018e-02, -1.5790e-02, -1.8899e-02, -2.0817e-02, -2.4259e-02,\n",
      "        -1.9407e-02, -2.0501e-02, -1.9444e-02, -1.6278e-02], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "# model.eval()\n",
    "# 2350 = 192 + 336 + 1822\n",
    "\n",
    "# x, y = torch.from_numpy(bindata[\"Xstd\"]), torch.from_numpy(bindata[\"Ystd\"])\n",
    "# with torch.no_grad():\n",
    "#     pred = model.forward(x[:192], x[192:528], x[528:])\n",
    "#     # predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "#     print(f'Predicted: {pred}')\n",
    "#     print(f\"Actual: {y}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2350,) [-0.60543  0.40897  0.19042 -0.65405  0.28228  0.40573  0.32636 -0.09081\n",
      " -0.31171 -0.26593  0.21367 -0.28124 -0.47571  0.11879 -0.12313 -0.57528\n",
      "  0.086    0.15045 -0.63428  0.14261]\n",
      "(214,) [0.95537 0.79754 0.50043 0.7199  0.58381 0.49715 0.80825 0.69686 0.54392\n",
      " 0.85541 0.74866 0.62923 0.92144 0.81804 0.71969 0.58138 0.61554 0.73037\n",
      " 0.74607 0.75013]\n"
     ]
    }
   ],
   "source": [
    "Xmean = np.fromfile(\"Xmean.bin\", dtype=np.float32)\n",
    "Ymean = np.fromfile(\"Ymean.bin\", dtype=np.float32)\n",
    "print(Xmean.shape, Xmean[-20:])\n",
    "print(Ymean.shape, Ymean[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([ 0.0000,  0.0000,  0.0000, -0.2251,  0.1177, -0.0623, -0.4225,  0.2583,\n",
      "        -0.1927, -0.7196,  0.3673, -0.3482, -1.0511,  0.4581, -0.4679, -1.0769])\n",
      "Actual: tensor([ 0.0000,  0.0000,  0.0000, -0.2251,  0.1177, -0.0623, -0.4225,  0.2583,\n",
      "        -0.1927, -0.7196,  0.3673, -0.3482, -1.0511,  0.4581, -0.4679, -1.0769],\n",
      "       device='cuda:0')\n",
      "Predicted: tensor([-0.0098,  0.0049,  0.0058, -0.0034, -0.0021, -0.0215, -0.2200,  0.0436,\n",
      "        -0.1534, -0.4226,  0.0810, -0.0447, -0.4017,  0.2072,  0.0113,  0.0012],\n",
      "       device='cuda:0')\n",
      "Loss: 0.20533616840839386\n"
     ]
    }
   ],
   "source": [
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = nn.MSELoss()\n",
    "model.to(device)\n",
    "\n",
    "def test(bindata, model):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        x, y = torch.from_numpy(bindata[\"Xmean\"]), torch.from_numpy(bindata[\"Ymean\"])\n",
    "        pose = x[:192].to(device).unsqueeze(0)\n",
    "        traj = x[192:528].to(device).unsqueeze(0)\n",
    "        sensor = x[528:].to(device).unsqueeze(0)\n",
    "        y = y.to(device).unsqueeze(0)\n",
    "        pred = model(pose, traj, sensor)\n",
    "        test_loss = loss_fn(pred, y)\n",
    "    \n",
    "    torch.set_printoptions(threshold=10_000)\n",
    "    print(f\"Input: {x[:16]}\")\n",
    "    print(f\"Actual: {y.squeeze(0)[:16]}\")\n",
    "    print(f'Predicted: {pred.squeeze(0)[:16]}')\n",
    "    print(f\"Loss: {test_loss}\")\n",
    "\n",
    "test(bindata, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
